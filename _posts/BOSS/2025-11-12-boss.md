---
layout:     post
title:      项目总结
subtitle:   
date:       2024-11-15
author:     phoenixZ
header-img: /img/oip3.jpg
catalog: true
tags:
    - boss
---
# 航迹飞行区域覆盖

## 区域覆盖

根据区域： 圆形、矩形 取最小的X，Y；

**圆形的话：**

1. 先根据GPS2XYZ，  利用圆心和半径得到 Xmin， Xmax， Ymin， Ymax
2. 根据间隔n米一个点的原则，从左下到左上，S形走位，并且要判断点在不在圆形内(勾股定理， 点与圆心点的平方距离)

**多边形的话：**

1. 直接可以得到Xmin, Ymin
2. 根据间隔n米一个点的原则，判断生成多少个点

{% highlight cpp %}
void algo_search::generatePoints()
{

    all_point.clear();

    int x_count = (xMax - xMin) / per_distance + 1;

    int y_count = (yMax - yMin) / per_distance + 1;

    all_point.emplace_back(xMin, yMin, mission_get.missions[0].height);

    double y_start = yMin;

    for (int j = 1; j <= y_count; ++j)
    {

    y_start += per_distance;

    all_point.emplace_back(xMin, y_start, mission_get.missions[0].height);
    }

    double x_start = xMin;

    for (int i = 1; i <= x_count; ++i)

    {

    x_start += per_distance;

    all_point.emplace_back(x_start, y_start, mission_get.missions[0].height);

    for (int j = 1; j <= y_count; ++j)
        {

    if ((i % 2) == 1)

    {

    y_start -= per_distance;
            }

    else
            {

    y_start += per_distance;
            }

    all_point.emplace_back(x_start, y_start, mission_get.missions[0].height);
        }
    }
}
{% endhighlight %}

## PID

PID 是比例-积分-微分控制

我是这样理解的： 想象有一桶水， 当前水量0.2L, 目标水量1L

**对于比例控制**：

U = Kp * (目标值 - 当前值)， 假设1s加一次水， 一次加0.5L

第一帧：U = 0.5 * 0.8 = 0.4,  diff = 1-0.6 = 0.4
第二帧：U = 0.5 * 0.4 = 0.2,  diff = 1-0.8 = 0.2
第三帧：U = 0.5 * 0.2 = 0.1,  diff = 1-0.9 = 0.1
...

但是如果考虑水缸会漏水的情况，就会有稳态误差的形成， 也就是稳定在0.8L不往上增加了

**这时需要引入积分控制**

U = Kp × diff + Ki × 累积的diff

增加每次的输入，防止稳态误差

**对于微分控制**

U = Kp × diff + Ki × 累积的diff + Kp*(diff / dt)

微分控制主要是防止震荡

{% highlight cpp %}
float PID::computeVal(const float &cur_status, const float &target_status, const float &delta_t)
{
    float val_p, val_i, val_d, error, res_val;

    error = target_status - cur_status;

    val_p = error;

    val_i += error * delta_t;
    val_d = (error - last_error_) / delta_t;

    last_error_ = error;

    //比例控制 + 积分控制 + 微分控制
    res_val = kp_ * val_p + ki_ * val_i + kd_ * val_d;

    return res_val;
}
{% endhighlight %}

# 目标跟随与防丢失策略

## 模型部署

## 卡尔曼滤波

卡尔曼滤波器是一种用于**线性**系统状态估计的递归算法。它通过融合带有噪声的测量值和一个包含系统动态的预测模型，来产生对系统状态的最优估计。这里的“最优”是指在最小均方误差 (Minimum Mean Square Error, MMSE) 意义下。

### 核心假设

1. **系统是线性的。**
2. **过程噪声和测量噪声是零均值、高斯分布（正态分布）的白噪声。**

### 1. 系统模型 (System Model)

一个离散时间线性系统可以表示为：

* 状态转移方程 (Prediction):
  $$
  x_k = F_{k-1} x_{k-1} + B_{k-1} u_{k-1} + w_{k-1}
  $$
* 测量方程 (Update):
  $$
  z_k = H_k x_k + v_k
  $$

| **符号**        | **描述**                                                                           |
| --------------------- | ---------------------------------------------------------------------------------------- |
| **$x_k$**     | **$k$**时刻的**系统状态向量**                                              |
| **$x_{k-1}$** | **$k-1$**时刻的系统状态向量                                                            |
| **$F_{k-1}$** | **状态转移矩阵**(或 **系统矩阵** )，将**$x_{k-1}$**映射到**$x_k$** |
| **$u_{k-1}$** | **$k-1$**时刻的**控制输入向量**                                            |
| **$B_{k-1}$** | **控制输入矩阵**(或 **控制矩阵** )，将**$u_{k-1}$**映射到**$x_k$** |
| **$w_{k-1}$** | **过程噪声向量** ，假设**$w_{k-1} \sim N(0, Q_{k-1})$**                          |
| **$Q_{k-1}$** | **过程噪声协方差矩阵**                                                             |
| **$z_k$**     | **$k$**时刻的**测量向量**                                                  |
| **$H_k$**     | **观测矩阵**(或 **测量矩阵** )，将**$x_k$**映射到**$z_k$**         |
| **$v_k$**     | **测量噪声向量** ，假设**$v_k \sim N(0, R_k)$**                                  |
| **$R_k$**     | **测量噪声协方差矩阵**                                                             |

### 2. 核心公式 (Recursive Steps)

KF 包含两个阶段：**预测 (Prediction)** 和  **更新 (Update)** 。

#### A. 预测阶段 (Time Update)

利用系统的动态模型来预测下一时刻的状态和误差协方差。

1. 先验状态估计 (Predicted State Estimate):
   $$
   \hat{x}_k^- = F_{k-1} \hat{x}_{k-1}^+ + B_{k-1} u_{k-1}
   $$
2. 先验误差协方差 (Predicted Covariance Estimate):
   $$
   P_k^- = F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1}
   $$

| **符号**                | **描述**                                                              |
| ----------------------------- | --------------------------------------------------------------------------- |
| **$\hat{x}_k^-$**     | **$k$**时刻的**先验**状态估计 (未结合**$z_k$**测量值)       |
| **$\hat{x}_{k-1}^+$** | **$k-1$**时刻的**后验**状态估计 (已结合**$z_{k-1}$**测量值) |
| **$P_k^-$**           | **$k$**时刻的**先验**误差协方差矩阵                           |
| **$P_{k-1}^+$**       | **$k-1$**时刻的**后验**误差协方差矩阵                         |

#### B. 更新阶段 (Measurement Update)

利用当前时刻的测量值 **$z_k$** 来修正先验估计，得到更准确的后验估计。

1. 卡尔曼增益 (Kalman Gain):
   $$
   K_k = P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1}
   $$
2. 后验状态估计 (Updated State Estimate):
   $$
   \hat{x}_k^+ = \hat{x}_k^- + K_k (z_k - H_k \hat{x}_k^-)
   $$
3. 后验误差协方差 (Updated Covariance Estimate):
   $$
   P_k^+ = (I - K_k H_k) P_k^-
   $$

| **符号**            | **描述**                                                        |
| ------------------------- | --------------------------------------------------------------------- |
| **$K_k$**         | **卡尔曼增益矩阵** ，用于平衡预测和测量之间的权重               |
| **$\hat{x}_k^+$** | **$k$**时刻的**后验**状态估计 (已结合**$z_k$**测量值) |
| **$P_k^+$**       | **$k$**时刻的**后验**误差协方差矩阵                     |
| **$I$**           | 适当维度的**单位矩阵**                                          |

## EKF

当系统模型（状态转移方程或测量方程，或两者）是**非线性**时，标准的 KF 就不能直接使用了。EKF 是 KF 针对非线性系统的一种近似解决方案。

### 核心思想

EKF 的核心思想是：在每次状态预测和测量更新时，用**一阶泰勒级数展开**来近似非线性系统，从而将非线性问题 **局部线性化** ，然后应用标准的 KF 公式。

### 1. 系统模型 (Nonlinear System Model)

非线性离散时间系统可以表示为：

* 状态转移方程 (Prediction):
  $$
  x_k = f(x_{k-1}, u_{k-1}) + w_{k-1}
  $$
* 测量方程 (Update):
  $$
  z_k = h(x_k) + v_k
  $$

| **符号**         | **描述**               |
| ---------------------- | ---------------------------- |
| **$f(\cdot)$** | **非线性**状态转移函数 |
| **$h(\cdot)$** | **非线性**测量函数     |

### 2. 核心公式 (Recursive Steps for EKF)

EKF 最大的区别在于，它用**雅可比矩阵** (Jacobian Matrix) 来代替 KF 中的 **$F$** 和 **$H$** 矩阵。

#### A. 预测阶段 (Time Update)

1. 先验状态估计:

   $$
   \hat{x}_k^- = f(\hat{x}_{k-1}^+, u_{k-1})
   $$

   (注意：这里直接将后验状态估计 $\hat{x}_{k-1}^+$ 代入非线性函数 $f$。)
2. 线性化：计算状态转移雅可比矩阵 $F_{k-1}$，这是 $f(\cdot)$ 关于状态 $x$ 的偏导数。

   $$
   F_{k-1} = \left.\frac{\partial f}{\partial x}\right|_{\hat{x}_{k-1}^+, u_{k-1}}
   $$
3. 先验误差协方差:

   $$
   P_k^- = F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1}
   $$

   (公式结构与 KF 相同，但 $F_{k-1}$ 是雅可比矩阵。)

#### B. 更新阶段 (Measurement Update)

1. 线性化：计算观测雅可比矩阵 $H_k$，这是 $h(\cdot)$ 关于状态 $x$ 的偏导数。

   $$
   H_k = \left.\frac{\partial h}{\partial x}\right|_{\hat{x}_k^-}
   $$

   (在预测状态 $\hat{x}_k^-$ 处进行线性化。)
2. 卡尔曼增益:

   $$
   K_k = P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1}
   $$

   (公式结构与 KF 相同，但 $H_k$ 是雅可比矩阵。)
3. 后验状态估计:

   $$
   \hat{x}_k^+ = \hat{x}_k^- + K_k (z_k - h(\hat{x}_k^-))
   $$

   (注意：这里的测量残差是用实际测量 $z_k$ 减去通过非线性函数 $h(\cdot)$ 得到的预测测量。)
4. 后验误差协方差:

   $$
   P_k^+ = (I - K_k H_k) P_k^-
   $$

## 单目测距

### 相机模型

#### 1. 像素坐标转图像坐标

将像素坐标 (u, v) 转换为图像坐标 (x, y) 的过程如下：

![像素与图像坐标系示意图]({{ site.baseurl }}/img/像素转图像.png)

数学表达式为：

$$
\left\{
\begin{array}{l}
  x = \frac{u - u_0}{d_x} \\[8pt]
  y = \frac{v - v_0}{d_y} \tag{1}
\end{array}
\right.
$$

> 说明：
> UV 为像素坐标系，XY 为图像坐标系。
> o是图像中心
> (u, v) 表示原始像素坐标，(x, y) 表示转换后的图像坐标；d_x 与 d_y 分别为像素的尺寸。

---

#### 2. 图像坐标转相机坐标

图像坐标转换为相机坐标的示意如下：

![图像坐标转相机坐标]({{ site.baseurl }}/img/图像转相机.png)

转换公式基于相似三角形原理为：

$$
\left\{
\begin{array}{l}
  x_c = \frac{Z_c \cdot x}{f} \\[8pt]
  y_c = \frac{Z_c \cdot y}{f} \tag{1}
\end{array}
\right.
$$

> 说明：
> – 公式中 Z_c 表示相机与目标之间的距离； 在相机坐标系中是沿相机Z轴的距离
> – 在归一化坐标系下，f 的影响可以忽略，从而简化转换过程。

### 测距算法

![测距模型]({{ site.baseurl }}/img/测距模型.png)

#### 1. 计算公式

$$
\begin{aligned}
D      &= H \cdot \tan(\alpha - \beta) \quad \text{(1)} \\[8pt]
\alpha &= \frac{\pi}{2} - pitch \quad \text{(2)} \\[8pt]
\beta  &= \arctan(y) \quad \text{(3)}
\end{aligned}
$$

> **角度说明：**
> **$\alpha$**：相机光轴与水平面的夹角。当云台 pitch 角向下倾斜时，$\alpha = \frac{\pi}{2} - pitch$ 表示从水平线到相机光轴的角度。
> **$\beta$**：从相机光轴到图像上目标投影点的角度。在相机坐标系中，该角度由归一化后的图像坐标 $y$ 计算得到，$\beta = \arctan(y)$。
> 因此，$(\alpha - \beta)$ 表示从水平线到目标投影点的角度，用于计算目标在水平方向上的距离。

#### 2. bata计算原理

![β 图]({{ site.baseurl }}/img/β.png)

> 图中：0 表示光心，p 为图像上的投影点

下面让我解释一下 $\beta$ 角的计算原理：

在相机成像原理中，$\beta$ 角表示从相机光心指向图像平面上某投影点的角度，该角度可以通过图像坐标 $y$ 来计算。

**为什么 $\beta = \arctan(y)$？**原因如下：

1. 图像坐标系中的 $y$ 值已通过相机内参矩阵归一化处理。
2. 因此，$\beta$ 就是该三角形中的角，其计算公式自然为 $\arctan(y)$。

#### 3. 计算深度

根据上述公式 (1)，D 表示 FLU 坐标系中向前的距离（对应于 flu_x）。

利用 flu_x 和勾股定理，可进一步计算深度（实际距离）：

$$
depth = \sqrt{flu_x^2 + H^2}.
$$

#### 4. 计算 yaw 角

![yaw 图]({{ site.baseurl }}/img/yaw.png)

> 正确的 yaw 角应为绿色虚线与 Zc 的夹角, 即是相机坐标系下真实目标与光心的夹角

$$
\begin{aligned}
yaw &= \arctan\left(\frac{flu_y}{flu_x}\right) \\[8pt]
    &= \arctan\left(\frac{y \cdot dist}{flu_x}\right).
\end{aligned}
$$

#### 总结

1. 利用几何关系解算位置 FLU_x = H * tan(云台向下的角度 + 接地点在图像平面投影点与相机光轴的夹角)
2. 接地点在图像平面投影点与相机光轴的夹角可以用 atan(y) 计算得到 (pitch)
3. 然后计算深度， 根据勾股定理， depth = H 平方 + FLU_x的平方然后开方
4. 计算相机坐标系下， 目标点与相机光轴的夹角(yaw)
5. 然后利用图像坐标转世界坐标计算FLU_y， 用图像点X来转换，因为x表示目标点在图像平面偏离光轴的左右程度;
6. 云台控制也利用pitch和yaw将目标保持在画面中心

## 防丢失策略

1. 跟随过程中往前走一段距离
2. 以跟随距离为半径，丢失前的目标点为圆形进行环绕搜索
3. 如果算出来的pitch和yaw接近了阈值就适当抬高、降低无人机

{% highlight cpp %}

void Follow::geratePoints()
{
    circle_angles_.clear();
    float start_angle = atan2(cur_pos_.y - target_pos_.y, cur_pos_.x - target_pos_.x) * (180.0f / M_PI);
    for (int i = 0; i < 360 / std::abs(circle_spd_); ++i) {
        circle_angles_.emplace_back((start_angle + i * circle_spd_) * (M_PI / 180.0f));
    }
    std::reverse(circle_angles_.begin(), circle_angles_.end());
}
{% endhighlight %}

# DJI PSDK

## DJI Eport 替换方案

1. 使用orin NX 作负载的时候， 不用配置USB BULK, 选择硬件连接方式DJI_USE_UART_AND_NETWORK_DEVICE
2. 使用rk3588s 作为负载时，不参照官方建议配置rndis， 直接使用网卡

   - 使用lsusb 获取网卡对应的VID和PID
   - 获取3588对应网口的名称， 修改配置文件对应配置
   - 检查串口名称，eg. `/dev/ttyUSB0`    对应修改hal_uart.h中的 `LINUX_UART_DEV1`

## 双路拉流

1. SDK模块初始化， `DjiCameraManager_Init()` 和 `DjiLiveview_Init()`
2. `DjiPayloadCamera_GetVideoStreamRemoteAddress(ipAddr, &port);`：获取 DJI 负载相机视频流的远程 IP 地址和端口号
3. 可见光、红外同步拉流

   - 启动拉流， 然后用H.264解码
   - 设计队列为帧-时间戳 std::queue<std::pair<cv::Mat, int64_t>>
   - 比较两个队列中最老帧的时间戳，丢弃时间戳较老的帧，直到两个队列的最老帧的时间戳近似相等(误差几ms)

   {% highlight cpp %}

      DjiLiveview_StartH264Stream(DJI_LIVEVIEW_CAMERA_POSITION_NO_1,
                           DJI_LIVEVIEW_CAMERA_SOURCE_DEFAULT,
                           &StreamDecoder::startMainCameraDecoding);

      DjiLiveview_StartH264Stream(DJI_LIVEVIEW_CAMERA_POSITION_NO_1,
                            DJI_LIVEVIEW_CAMERA_SOURCE_M3T_IR,
                            &StreamDecoder::startIrCameraDecoding);

    {% endhighlight %}


   {% highlight cpp %}

      bool StreamDecoder::getSynchronizedFrames(cv::Mat& mainFrame, cv::Mat& irFrame, int syncToleranceMs)
      {
         std::lock_guard<std::mutex> lock(frameMutex);
         const int tolerance = syncToleranceMs; // 容忍时间（毫秒）

         // 检查是否有足够的帧进行同步
         while (!mainFrameQueue.empty() && !irFrameQueue.empty())
         {
            // 获取队列头部帧的时间戳
            int64_t mainTs = mainFrameQueue.front().timestamp;
            int64_t irTs   = irFrameQueue.front().timestamp;
            
            // **注意**：PTS 的单位通常不是毫秒。
            // 例如：long ts_ms = ts * av_q2d(time_base) * 1000;

            long diff = std::abs(mainTs - irTs);

            if (diff <= tolerance)
            {
                  // **同步成功**：时间戳匹配，取出帧并返回
                  mainFrame = mainFrameQueue.front().frame;
                  irFrame   = irFrameQueue.front().frame;

                  mainFrameQueue.pop();
                  irFrameQueue.pop();

                  return true;
            }
            else if (mainTs < irTs)
            {
                  std::cout << "Dropping Main Frame. Ts diff: " << diff << "ms." << std::endl;
                  mainFrameQueue.pop();
            }
            else // irTs < mainTs
            {
                  std::cout << "Dropping IR Frame. Ts diff: " << diff << "ms." << std::endl;
                  irFrameQueue.pop();
            }
         }

         // 如果任一队列为空，则无法同步
         return false;
      }

   {% endhighlight %}


## 自定义协议MOP互联互通
1. MOP设置
   - PipelineChannelId 信道值设置为38583
   - PipelineDeviceType 信道设备类型设置为ONBOARD
   - TransmissionControlType 传输控制类型 设置为 UNRELIABLE
2. 智能盒子Mop协议主要由三部分组成：帧头、帧体（负载）、帧尾（校验）
3. 请求信息： fusion_module 0：双光 1. 地图 ， fusion_commad 0：停止 ， 1： 开始； 请求重新发送的图像块
4. 发送信息： ack_type 0： 状态， 1： 图像， data
   - fusion_result_type ：int8_t  表示是什么任务的
   - img_uuid：char 表示图像唯一性
   - seg_nums：uint16_t  图像分段数目
   - seg_current_num：uint16_t 当前分段数
   - seg_img_data：int8_t 当前分段图像内容
5. 解决丢包：
   - 选择性重传
   - 超时未收到ACK自动重传
   - 规定最大重传数和最大等待时间，不行放弃当前帧
   - 图像压缩成JPG格式压缩掉10%， 可以进一步压缩或者使用H.264来压缩

## 状态机

# 多无人车协同搜索

## 边界与视点生成

## 区域分配算法

## 路径规划

### 差速轮动力学模型

### Djikstra

### A*

### B样条曲线插值优化

## PID+puresuit控制
