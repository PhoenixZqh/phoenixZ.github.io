---
layout:     post
title:      项目总结
subtitle:   
date:       2025-11-15
author:     phoenixZ
header-img: /img/oip3.jpg
catalog: true
tags:
    - boss
---
# 航迹飞行区域覆盖

## 区域覆盖

根据区域： 圆形、矩形 取最小的X，Y；

**圆形的话：**

1. 先根据GPS2XYZ，  利用圆心和半径得到 Xmin， Xmax， Ymin， Ymax
2. 根据间隔n米一个点的原则，从左下到左上，S形走位，并且要判断点在不在圆形内(勾股定理， 点与圆心点的平方距离)

**多边形的话：**

1. 直接可以得到Xmin, Ymin
2. 根据间隔n米一个点的原则，判断生成多少个点

{% highlight cpp %}
void algo_search::generatePoints()
{

    all_point.clear();

    int x_count = (xMax - xMin) / per_distance + 1;

    int y_count = (yMax - yMin) / per_distance + 1;

    all_point.emplace_back(xMin, yMin, mission_get.missions[0].height);

    double y_start = yMin;

    for (int j = 1; j <= y_count; ++j)
    {

    y_start += per_distance;

    all_point.emplace_back(xMin, y_start, mission_get.missions[0].height);
    }

    double x_start = xMin;

    for (int i = 1; i <= x_count; ++i)

    {

    x_start += per_distance;

    all_point.emplace_back(x_start, y_start, mission_get.missions[0].height);

    for (int j = 1; j <= y_count; ++j)
        {

    if ((i % 2) == 1)

    {

    y_start -= per_distance;
            }

    else
            {

    y_start += per_distance;
            }

    all_point.emplace_back(x_start, y_start, mission_get.missions[0].height);
        }
    }
}
{% endhighlight %}

## PID

PID 是比例-积分-微分控制

我是这样理解的： 想象有一桶水， 当前水量0.2L, 目标水量1L

**对于比例控制**：

U = Kp * (目标值 - 当前值)， 假设1s加一次水， 一次加0.5L

第一帧：U = 0.5 * 0.8 = 0.4,  diff = 1-0.6 = 0.4
第二帧：U = 0.5 * 0.4 = 0.2,  diff = 1-0.8 = 0.2
第三帧：U = 0.5 * 0.2 = 0.1,  diff = 1-0.9 = 0.1
...

但是如果考虑水缸会漏水的情况，就会有稳态误差的形成， 也就是稳定在0.8L不往上增加了

**这时需要引入积分控制**

U = Kp × diff + Ki × 累积的diff

增加每次的输入，防止稳态误差

**对于微分控制**

U = Kp × diff + Ki × 累积的diff + Kp*(diff / dt)

微分控制主要是防止震荡

{% highlight cpp %}
float PID::computeVal(const float &cur_status, const float &target_status, const float &delta_t)
{
    float val_p, val_i, val_d, error, res_val;

    error = target_status - cur_status;

    val_p = error;

    val_i += error * delta_t;
    val_d = (error - last_error_) / delta_t;

    last_error_ = error;

    //比例控制 + 积分控制 + 微分控制
    res_val = kp_ * val_p + ki_ * val_i + kd_ * val_d;

    return res_val;
}
{% endhighlight %}

# 无人机避障

> 相比建图感知规划，该方法把“求最短路”换成“求最大成功概率路径”。核心思路是：
>
> 1. 局部确定性——利用感知到的体素阻塞信息，精准淘汰不可通行轨迹。
> 2. 全局概率性——根据当前姿态与目标姿态的差值和权重计算得分，保持整体趋近目标。
> 3. 这两者叠加即可快速挑出一条安全、可达、概率最高的轨迹。

## 预先生成轨迹和邻接表

### 轨迹生成

| 步骤                              | 参数（经典配置）                                                                                       | 说明                                                       | 生成文件                                                                  |
| --------------------------------- | ------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------- | ------------------------------------------------------------------------- |
| 1. 分组（35 个路径组）            | 水平 ±27°，步长 13.5° → 5 个 `<br>`垂直 ±18°，步长 9° → 5 个 `<br>`→ 5×7 或 7×5 = 35 组 | 每个组代表一个“大方向”（左转、直飞、右转、上仰、下俯等） | `startPaths.ply`（35 条代表轨迹的第一段，用于在线执行）                 |
| 2. 每组内再细分（35×35=1225 条） | 第 1 段：大范围偏角 `<br>`第 2 段：在第 1 段基础上 ±27°×0.65 `<br>`第 3 段：再 ±27°×0.65²   | 形成三层“漏斗式”采样，越往前越细、越密集覆盖             | `paths.ply`（全部 42,875 条完整轨迹，用于建邻接表）                     |
| 3. 生成方式                       | 三段式三次样条（cubic spline）`<br>`每段 3 米，总长 9 米                                             | 保证轨迹平滑、可被无人机精确跟踪                           | `pathList.ply`（每条轨迹的终点坐标 + path_id + group_id，用于在线打分） |

### 邻接表生成

   只要轨迹上的点经过了体素， 则认为两个是关联的， 体素体积0.1x0.1x0.1

| 步骤                    | 详细说明                                                                                                 | 经典配置参数（来自代码）                                                                                                     | 对应文件/数据结构                                                         |
| ----------------------- | -------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| 1. 空间体素化           | 将局部规划空间划分为三维网格（体素），作为碰撞检查的基本单元                                             | 体素大小：0.2 m `<br>`X：46 个（0∼9 m）`<br>`Y：126 个（±6.25 m）`<br>`Z：47 个（±2.3 m）`<br>`总数：≈272,844 个 | `correspondences.txt`（生成输出）`<br>correspondences_`（运行时加载） |
| 安全裕度                | 通过距离相关的 `scale_y` / `scale_z` 缩放，使靠近传感器的体素在横/纵方向被放大，保证安全裕度         | `scale_y` / `scale_z` 计算：`(x / 总深度) + (无人机尺寸 / …)`                                                         | -                                                                         |
| 2. 范围查询（核心关联） | 对每个体素中心点执行球形范围搜索（`rangesearch`）                                                      | 搜索半径：1.5 m（≈ 无人机安全半径 + 余量）`<br>`搜索维度：3D（Z 轴额外缩放）                                              | 预生成轨迹点 `pathAll`                                                  |
| 3. 列表写入与格式       | 将命中的轨迹点转换为路径 ID，去重后写入文件供在线查询                                                    | 去重：同一条轨迹多次穿过球体只记一次                                                                                         | -                                                                         |
| 文件格式                | 二进制格式，保证文件小且读取快 `<br>[体素ID(int32)] [pathID1(int16)] [pathID2(int16)] ... [-1(int16)]` | `correspondences.bin` / `correspondences.txt`                                                                            | 列表以 `-1` 结尾                                                        |

## 障碍物检测

一条轨迹如果被 ≥ `obstacle_num_`（通常是 1 或 2）个点云点“投票”说它会撞，就判为不可通行直接抛弃。投票链路：点云点投到体素 → 查离线邻接表 → 给对应轨迹投票。

- **放大障碍物**：近距离点会按照无人机几何尺寸放大影响范围。
- **局部确定性**：撞就是 0，可通行就是 1，逻辑简单可靠。

计算在局部点 x 处的水平和垂直缩放因子：左右缩小系数 = 深度 / 总深度 + (飞机宽度 / 总宽度) * ((总深度 - 深度) / 总深度)

1. 深度 / 总深度，深度越大，这个比例就越接近1，点离视觉传感器越远
2. (飞机宽度 / 总宽度)：它表示无人机的宽度相对于整个局部区域的宽度的比例，((总深度 - 深度) / 总深度) 这一部分表示深度相对于总深度的反比例

- 当点的深度很大时，第一部分接近1，表示点在深度上远离视觉传感器，而第二部分较小，因为深度相对于总深度很大，所以无人机的宽度对通行性的影响较小。
- 当点的深度较小时，第一部分接近0，表示点在深度上靠近视觉传感器，而第二部分较大，因为深度相对于总深度较小，所以无人机的宽度对通行性的影响较大

{% highlight cpp %}
void LocalPlanner::CalculateClearPath(pcl::PointCloud[pcl::PointXYZ](pcl::PointXYZ)::Ptr local_points, float path_scalar)
{
   int local_pts_size = local_points->size();
   for (int i = 0; i < local_pts_size; ++i)
   {
      float x = local_points->points[i].x / path_scalar; // 点坐标按 path_scalar 归一化
      float y = local_points->points[i].y / path_scalar;
      float z = local_points->points[i].z / path_scalar;

    // 深度相关缩放：近距离点会放大无人机宽/高，扩大碰撞体积
      float scale_y = x / grid_offset_x_ + uav_width_ / grid_offset_y_ * (grid_offset_x_ - x) / grid_offset_x_;
      float scale_z = x / grid_offset_x_ + uav_height_ / grid_offset_z_ * (grid_offset_x_ - x) / grid_offset_x_;

    // 计算所在体素索引
      int index_x = static_cast`<int>`((grid_offset_x_ + grid_size_ / 2.0f - x) / grid_size_);
      int index_y = static_cast `<int>`((grid_offset_y_ + grid_size_ / 2.0f - y / scale_y) / grid_size_);
      int index_z = static_cast `<int>`((grid_offset_z_ + grid_size_ / 2.0f - z / scale_z) / grid_size_);

    if (index_x >= 0 && index_x < grid_num_x_ && index_y >= 0 && index_y < grid_num_y_ && index_z >= 0 && index_z < grid_num_z_)
      {
         // 查邻接表并给路径投票
         int index         = grid_num_z_ * grid_num_y_ * index_x + grid_num_z_ * index_y + index_z;
         int grid_path_num = correspondences_[index].size();
         for (int j = 0; j < grid_path_num; ++j)
         {
            clear_path_[correspondences_[index][j]] += 1;
         }
      }
   }
}
{% endhighlight %}

## 最佳路径生成

无预设地图方式，启发式得分：

$$
\text{score} = \bigl(1 - w_{\text{pitch}} \cdot \Delta_{\text{pitch}}\bigr) \cdot \bigl(1 - w_{\text{yaw}} \cdot \Delta_{\text{yaw}}\bigr)
$$

{% highlight cpp %}
   int LocalPlanner::ChoosePath(Eigen::Vector3f local_goal)
   {
      // 计算局部目标点的俯仰角和偏航角，以便后续与路径末端的角度进行比较
      float goal_pitch = -atan2(local_goal[2], sqrt(local_goal[0] * local_goal[0] + local_goal[1] * local_goal[1])) * 180.0 / M_PI;
      float goal_yaw = atan2(local_goal[1], local_goal[0]) * 180.0 / M_PI;

    int clear_path_size = clear_path_.size();
      for (int i = 0; i < clear_path_size; ++i)
      {
         if (clear_path_[i] >= obstacle_num_) // 该路径点云超过阈值，予以舍弃
         {
               continue;
         }

    // 计算目标俯仰角和路径末端俯仰角之间的差异
         float pitch_diff = std::abs(goal_pitch - end_pitch_list_[i]);
         float yaw_diff = std::abs(goal_yaw - end_yaw_list_[i]);
         // 路径与目标之间的匹配度:受到俯仰角权重和偏航角权重的影响
         float score = (1.0f - pitch_weight_ * pitch_diff) * (1.0f - yaw_weight_ * yaw_diff);
         score = score > 0 ? score : 0;
         if(last_path_group_ == i) score *= last_path_gain_;
         group_score_[path_list_[i]] += (score + 1e-6); // 计算每组的累计得分
      }

    // 选择得分最高的路径组
      float max_score = 1e-6;
      int select_path_group = -1;
      int group_size = group_score_.size();
      for (int i = 0; i < group_size; ++i)
      {
         if (max_score < group_score_[i])
         {
               max_score = group_score_[i];
               select_path_group = i;
               // std::cout << "path max_score is: " << max_score << std::endl;
         }
      }

    last_path_group_ = select_path_group;
      return select_path_group;
   }

{% endhighlight %}

## 深度图像转点云

{% highlight cpp %}
   pcl::PointCloud[pcl::PointXYZ](pcl::PointXYZ)::Ptr ObjectPoints::GetObjectPoints(
      const cv::Mat &depth,                                 // 输入：当前帧深度图（CV_16U，单位毫米）
      const nav_msgs::OdometryConstPtr& odom,               // 输入：当前时刻无人机位姿（视觉里程计或融合位姿）
      bool isFront)                                         // 输入：是否是前视相机（用于后面显示，不影响点云生成）
   {
      local_points_->clear();                               // 清空上一次的原始点云缓存
      int rows = depth.rows;                                // 深度图高度（例如 480）
      int cols = depth.cols;                                // 深度图宽度（例如 640）

    // 第一步：遍历深度图所有像素（跳采样提速）
      for (int i = 0; i < rows; i += skip_step_)            // 垂直方向每 skip_step_ 个像素取一个（常见 2~4）
      {
         auto row_ptr = depth.ptr<uint16_t>(i);            // 获取第 i 行的指针（高效访问像素）
         for (int j = 0; j < cols; j += skip_step_)        // 水平方向也跳采样
         {
               float depth = row_ptr[j] * depth_gain_;       // 把毫米级像素值转成米（depth_gain_ 通常是 0.001）
               if (depth > max_depth_ || depth < min_depth_) continue;  // 超出有效深度范围的点直接扔掉（常见 0.5~10m）

    // 核心：针孔相机模型反投影，把像素(u,v,depth) → 3D点(x,y,z)
               // X = depth                                     → 正前方就是X轴
               // Y = (cx - u) * depth / fx                     → 图像坐标系u向右，Y向左为正
               // Z = (cy - v) * depth / fy                     → 图像坐标系v向下，Z向上为正
               local_points_->emplace_back(
                  depth,                                      // x：正前方
                  (cx_ - j) * depth * inv_fx_,                // y：横向（左正右负）
                  (cy_ - i) * depth * inv_fy_                 // z：纵向（上正下负）
               );
         }
      }

    // 第二步：体素网格下采样（Voxel Grid Filter），进一步减少点数
      local_points_ds_->clear();                            // 清空中等点云缓存
      down_sample_filter_.setInputCloud(local_points_);     // 输入刚刚生成的原始点云
      down_sample_filter_.filter(*local_points_ds_);        // 输出：每个0.2m体素内只保留一个代表点

    // 第三步：运动漂移 + 动态物体滤除（这才是真正的“黑魔法”）
      local_points_filter_->clear();                        // 准备存放最终干净点云
      auto to_global = GetMatrix2Global(odom);              // 当前相机到世界坐标系的变换矩阵（4x4）

    // 只有不是第一帧才执行滤除（需要上一帧做对比）
      if(get_first_frame_) {
         // 遍历所有下采样后的点
         for(auto pt : local_points_ds_->points) {
               Eigen::Vector3f p(pt.x, pt.y, pt.z);          // 当前点在相机坐标系下
               p = to_global.block<3,3>(0,0) * p + to_global.block<3,1>(0,3); // 转到世界坐标系
               // 关键：把这个世界坐标点反投影回上一帧相机坐标系
               Eigen::Vector3f p_rev_proj = last_toGlobal_.inverse() * p;  // last_toGlobal_ 是上一帧的位姿

    // 反投影到上一帧图像坐标 (u,v)
               double vv = -p_rev_proj.z() / (inv_fy_ * p_rev_proj.x()) + cy_;  // v 坐标（向下为正）
               double uu = -p_rev_proj.y() / (inv_fx_ * p_rev_proj.x()) + cx_;  // u 坐标（向右为正）

    // 判断这个像素是否在图像范围内
               if (vv >= 0 && vv < rows && uu >= 0 && uu < cols) {
                  // 取上一帧该像素的深度值（米）
                  double last_depth_val = last_depth_.at<uint16_t>((int)vv, (int)uu) * depth_gain_;
                  // 计算同一个空间点在两帧中的深度差（理论上应该几乎相等）
                  double drift_dis = fabs(last_depth_val - p_rev_proj.x());

    // 如果深度差很小 → 说明是静态环境，点可靠 → 保留
                  if (drift_dis < depth_filter_tolerance_) {          // 常见阈值 0.3~0.5m
                     local_points_filter_->emplace_back(pt.x, pt.y, pt.z);
                  }
                  // 否则：可能是动态物体、里程计漂移、深度噪声 → 直接扔掉！
               }
         }
      }

    // 保存当前帧信息供下一帧使用
      depth.copyTo(last_depth_);                        // 当前深度图 → 存为上一帧
      last_toGlobal_ = to_global;                       // 当前位姿 → 存为上一帧位姿
      get_first_frame_ = true;                          // 标记：第一帧已经处理完了

    // 第四步：返回最终点云
      if(get_first_frame_) {
         fill_obstacle_show(isFront);                  // 可视化用（不影响逻辑）
         return local_points_filter_;                  // 第二帧之后返回“超级干净”的点云（已滤除漂移）
      } else {
         return local_points_ds_;                      // 第一帧没有上一帧可比，返回下采样点云
      }
   }
{% endhighlight %}

## 杆量映射

最终速度 (m/s) = (归一化杆量 [-1 ~ +1])³ × 最大速度系数

# 目标跟随与防丢失策略

## 模型部署

| 模型      | 尺寸                 | 平台      | 推理速度             | 线程数 |
| --------- | -------------------- | --------- | -------------------- | ------ |
| yoloV5s   | 960x960              | xavier NX | 50 (后处理放在CPU上) | 1      |
|           | 640x640              | rk3588    | 39                   | 1      |
|           | 640x640              | rk3588    | 120帧左右            | 3      |
|           | 1280x1280            | rk3588    | 10                   | 1      |
| nanotrack | 127x127<br />255x255 | rk3588    | 125帧左右            | 1      |
| nanotrack | 127x127<br />255x255 | rk3588    | 200帧 （蒸馏）       | 1      |

## 防丢失整体逻辑

### 可见性与安全性思路

- 以预测的目标位置为圆心，跟踪距离为半径生成圆环
  {% highlight cpp %}
  for (double theta = 0; theta <= 2 * M_PI; theta += 0.01)
  {
  observable_margin.emplace_back(observable_p + tracking_dist_ * Eigen::Vector3d(cos(theta), sin(theta), 0));  // 水平圆环
  }
  {% endhighlight cpp %}
- 设计启发函数引导搜索重点落在圆环上，在保证无碰撞的前提下得到路径点
  {% highlight cpp %}
  // 启发函数设计， 将到目标的距离投影到理想圆环上
  auto calulateHeuristic = [&](const NodePtr& ptr) {
  Eigen::Vector3i dp = end_idx - ptr->idx;  // 体素单位

  double dr     = dp.head(2).norm();   // 水平距离
  double lambda = 1 - stop_dist / dr;  // 权重
  double dx     = lambda * dp.x();     // 在圆环上则为0
  double dy     = lambda * dp.y();
  double dz     = dp.z();
  ptr->h        = fabs(dx) + fabs(dy) + abs(dz);
  double dx0    = (start_idx - end_idx).x();
  double dy0    = (start_idx - end_idx).y();
  double cross  = fabs(dx * dy0 - dy * dx0) + abs(dz);  //路径与直线的交叉程度
  ptr->h += 0.001 * cross;
  };
  {% endhighlight cpp %}
- 生成平滑的轨迹

### 防丢失策略

1. 跟随过程中往前走一段距离
2. 以跟随距离为半径，丢失前的目标点为圆形进行环绕搜索
3. 如果算出来的pitch和yaw接近了阈值就适当抬高、降低无人机

{% highlight cpp %}

void Follow::geratePoints()
{
    circle_angles_.clear();
    float start_angle = atan2(cur_pos_.y - target_pos_.y, cur_pos_.x - target_pos_.x) * (180.0f / M_PI);
    for (int i = 0; i < 360 / std::abs(circle_spd_); ++i) {
        circle_angles_.emplace_back((start_angle + i * circle_spd_) * (M_PI / 180.0f));
    }
    std::reverse(circle_angles_.begin(), circle_angles_.end());
}
{% endhighlight %}

## 卡尔曼滤波

卡尔曼滤波器是一种用于**线性**系统状态估计的递归算法。它结合带有噪声的测量值和一个包含系统动态的预测模型，来产生对系统状态的最优估计。

1. **系统是线性的。**
2. **过程噪声和测量噪声是零均值、高斯分布（正态分布）的白噪声。**
3. 为什么假设噪声是高斯白噪声？
   - 高斯白噪声：频率均匀覆盖、幅度服从正太分布
   - 高斯分布经过线性变换后依然是搞死分布，这样只需要维护均值和方差两个参数即可描述完整的概率分布
   - 噪声是高斯的前提下，KF是最优估计

### 1. 系统模型 (System Model)

一个离散时间线性系统可以表示为：

* 状态转移方程 (Prediction):
  $$
  x_k = F_{k-1} x_{k-1} + B_{k-1} u_{k-1} + w_{k-1}
  $$
* 测量方程 (Update):
  $$
  z_k = H_k x_k + v_k
  $$

| **符号**        | **描述**                                                                           |
| --------------------- | ---------------------------------------------------------------------------------------- |
| **$x_k$**     | **$k$**时刻的**系统状态向量**                                              |
| **$x_{k-1}$** | **$k-1$**时刻的系统状态向量                                                            |
| **$F_{k-1}$** | **状态转移矩阵**(或 **系统矩阵** )，将**$x_{k-1}$**映射到**$x_k$** |
| **$u_{k-1}$** | **$k-1$**时刻的**控制输入向量**                                            |
| **$B_{k-1}$** | **控制输入矩阵**(或 **控制矩阵** )，将**$u_{k-1}$**映射到**$x_k$** |
| **$w_{k-1}$** | **过程噪声向量** ，假设**$w_{k-1} \sim N(0, Q_{k-1})$**                          |
| **$Q_{k-1}$** | **过程噪声协方差矩阵**                                                             |
| **$z_k$**     | **$k$**时刻的**测量向量**                                                  |
| **$H_k$**     | **观测矩阵**(或 **测量矩阵** )，将**$x_k$**映射到**$z_k$**         |
| **$v_k$**     | **测量噪声向量** ，假设**$v_k \sim N(0, R_k)$**                                  |
| **$R_k$**     | **测量噪声协方差矩阵**                                                             |

### 2. 核心公式 (Recursive Steps)

KF 包含两个阶段：**预测 (Prediction)** 和  **更新 (Update)** 。

#### A. 预测阶段 (Time Update)

利用系统的动态模型来预测下一时刻的状态和误差协方差。

1. 先验状态估计 (Predicted State Estimate):
   $$
   \hat{x}_k^- = F_{k-1} \hat{x}_{k-1}^+ + B_{k-1} u_{k-1}
   $$
2. 先验误差协方差 (Predicted Covariance Estimate):
   $$
   P_k^- = F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1}
   $$

| **符号**                | **描述**                                                              |
| ----------------------------- | --------------------------------------------------------------------------- |
| **$\hat{x}_k^-$**     | **$k$**时刻的**先验**状态估计 (未结合**$z_k$**测量值)       |
| **$\hat{x}_{k-1}^+$** | **$k-1$**时刻的**后验**状态估计 (已结合**$z_{k-1}$**测量值) |
| **$P_k^-$**           | **$k$**时刻的**先验**误差协方差矩阵                           |
| **$P_{k-1}^+$**       | **$k-1$**时刻的**后验**误差协方差矩阵                         |

#### B. 更新阶段 (Measurement Update)

利用当前时刻的测量值 **$z_k$** 来修正先验估计，得到更准确的后验估计。

1. 卡尔曼增益 (Kalman Gain):
   $$
   K_k = P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1}
   $$
2. 后验状态估计 (Updated State Estimate):
   $$
   \hat{x}_k^+ = \hat{x}_k^- + K_k (z_k - H_k \hat{x}_k^-)
   $$
3. 后验误差协方差 (Updated Covariance Estimate):
   $$
   P_k^+ = (I - K_k H_k) P_k^-
   $$

| **符号**            | **描述**                                                        |
| ------------------------- | --------------------------------------------------------------------- |
| **$K_k$**         | **卡尔曼增益矩阵** ，用于平衡预测和测量之间的权重               |
| **$\hat{x}_k^+$** | **$k$**时刻的**后验**状态估计 (已结合**$z_k$**测量值) |
| **$P_k^+$**       | **$k$**时刻的**后验**误差协方差矩阵                     |
| **$I$**           | 适当维度的**单位矩阵**                                          |

### 调参经验

状态量设定的位置和速度6维， 采用CV恒定速度模型， Q是过程噪声，越大越不相信模型； R是测量噪声，越大越不相信测量

- 如果滤出来的过于平滑， 则增大Q， 或者减小R
- 如果滤出来的跳动比较大，则减小Q， 或者增大R

### 优化操作

1. 第一轮检测基于整张图像做，匹配到是危险目标的人之后进行跟踪，用卡尔曼滤波预测一个框
2. 后续检测基于预测框放大去做检测

   {% highlight cpp %}

   cv::Rect Sot::UpdateDetRoiCenter(const BboxXYAH &box, int image_width, int image_height, const float amplify)
   {
   float augment_range = box.alpha > 1? amplify * box.width : amplify * box.height;
   // if(augment_range < 320 ) augment_range = 320;
   if(augment_range > 960) augment_range = 960;

   int left = box.cx - augment_range / 2;
   int top = box.cy - augment_range / 2;

   if(left < 0)
   left =0;
   if(left > image_width - augment_range)
   left = image_width - augment_range;

   if(top < 0)
   top = 0;
   if(top > image_height - augment_range)
   top = image_height - augment_range;

   float right = left + augment_range;
   float bottom = top + augment_range;

   cv::Rect rect(cv::Point(left, top), cv::Point(right, bottom));
   return rect;
   }

   {% endhighlight cpp %}

### 代码

{% highlight cpp %}
   KF::KF(float delta_time, float sigma_pro_noise, float sigma_mea_noise) {
   setup(delta_time, sigma_pro_noise, sigma_mea_noise);
   }

   // 所有矩阵一次性在这里初始化，构造函数只调用这一个函数，方便后期改参数
   void KF::setup(float delta_time,
                  float sigma_pro_noise = 4.0f,      // 默认值：高速车辆常用 4~12
                  float sigma_mea_noise = 0.1f) {    // 默认值：毫米波雷达 ≈ 0.1m 量级

   // ==================== 状态转移矩阵 F (6×6) ====================
   // 恒速模型（Constant Velocity）：p_k = p_{k-1} + v_{k-1}·dt，v_k = v_{k-1}
   motion_mat_ = Eigen::Matrix<float, 6, 6>::Identity(6, 6);
   for (int i = 0; i < 3; ++i) {                     // 只改位置对速度的积分项
      motion_mat_(i, 3 + i) = delta_time;            // 第i个位置 = 上个位置 + 对应速度×dt
   }

   // ==================== 观测矩阵 H (3×6) ====================
   // 只观测位置，不观测速度（雷达/激光/视觉常见情况）
   update_mat_ = Eigen::Matrix<float, 3, 6>::Identity(3, 6);  // 前三列为1，其余为0
   // 等价于：update_mat_.block<3,3>(0,0) = I_3×3; 其余为0

   // ==================== 过程噪声协方差 Q (6×6) ====================
   // 采用经典“分段常加速度”模型（piece-wise constant white acceleration model）
   // 假设三个方向的加速度是相互独立的高斯白噪声
   Eigen::Matrix<float, 3, 3> qt;
   qt.setZero();
   qt(0, 0) = sigma_pro_noise;        // x方向加速度噪声功率
   qt(1, 1) = sigma_pro_noise;        // y方向
   qt(2, 2) = sigma_pro_noise / 4.f;   // z方向通常更平稳，给小一点（工业界常见经验）

   // 噪声到状态的映射矩阵 Γ（也叫 Wk）
   Eigen::Matrix<float, 6, 3> wk;
   wk.setZero();
   wk(0, 0) = delta_time * delta_time / 2.f;   // (1/2)dt² → 位置受加速度影响
   wk(1, 1) = delta_time * delta_time / 2.f;
   wk(2, 2) = delta_time * delta_time / 2.f;
   wk(3, 0) = delta_time;                      // dt      → 速度受加速度影响
   wk(4, 1) = delta_time;
   wk(5, 2) = delta_time;

   // Q = Γ·q·Γ^T    （最终的过程噪声协方差）
   motion_cov_ = wk * qt * wk.transpose();

   // ==================== 测量噪声协方差 R (3×3) ====================
   // 假设xyz三个方向测量噪声独立且同分布（实际项目可分别配置）
   measure_cov_ = Eigen::Matrix<float, 3, 3>::Identity(3, 3);
   measure_cov_(0, 0) = sigma_mea_noise;
   measure_cov_(1, 1) = sigma_mea_noise;
   measure_cov_(2, 2) = sigma_mea_noise;
   }

   void KF::Init(const TargetStatus &obj) {
   // 第一次看到目标时：位置用测量值，速度初始化为0
   mean_ << obj.x, obj.y, obj.z, 0, 0, 0;
   // 初始协方差给一个比较大的值，表示对初始状态不完全信任
   // 这里直接用一个周期的过程噪声（实际常乘以 10~1000）
   covariance_ = motion_cov_;
   }

   TargetStatus KF::Predict() {
   // 【预测步】无控制输入的恒速模型
   mean_ = motion_mat_ * mean_;                                      // x̂_k|k-1 = F·x̂_{k-1|k-1}

   covariance_ =
         motion_mat_ * covariance_ * motion_mat_.transpose() + motion_cov_;  // P_k|k-1 = F P F^T + Q

   TargetStatus obj(mean_);
   return obj;                                                       // 返回预测后的目标状态（常用于 coasting）
   }

   TargetStatus KF::Update(const TargetStatus &obj) {
   // 【更新步】
   Eigen::Matrix<float, 3, 1> mean_ret = update_mat_ * mean_;        // 预测的观测值 ẑ = H·x̂

   // 卡尔曼增益 K = P H^T (H P H^T + R)^(-1)
   auto kalman_gain =
         (covariance_ * update_mat_.transpose()) *
         (update_mat_ * covariance_ * update_mat_.transpose() + measure_cov_)
            .inverse();

   // 真实测量值
   Eigen::Matrix<float, 3, 1> measure;
   measure << obj.x, obj.y, obj.z;

   // 状态修正：x̂_k|k = x̂_k|k-1 + K·(z - ẑ)
   mean_ = mean_ + kalman_gain * (measure - mean_ret);

   // 协方差更新（经典形式，数值稳定性稍差但足够用）
   // 更稳健的写法：P = (I - K H) P (I - K H)^T + K R K^T   或直接用约瑟夫形式
   covariance_ = covariance_ - kalman_gain * update_mat_ * covariance_;

   TargetStatus obj_result(mean_);
   return obj_result;                                                // 返回融合后的最优估计
   }
{% endhighlight %}

## EKF

当系统模型（状态转移方程或测量方程，或两者）是**非线性**时，标准的 KF 就不能直接使用了。EKF 是 KF 针对非线性系统的一种近似解决方案。

### 核心思想

EKF 的核心思想是：在每次状态预测和测量更新时，用**一阶泰勒级数展开**来近似非线性系统，从而将非线性问题 **局部线性化** ，然后应用标准的 KF 公式。

### 1. 系统模型 (Nonlinear System Model)

非线性离散时间系统可以表示为：

* 状态转移方程 (Prediction):
  $$
  x_k = f(x_{k-1}, u_{k-1}) + w_{k-1}
  $$
* 测量方程 (Update):
  $$
  z_k = h(x_k) + v_k
  $$

| **符号**         | **描述**               |
| ---------------------- | ---------------------------- |
| **$f(\cdot)$** | **非线性**状态转移函数 |
| **$h(\cdot)$** | **非线性**测量函数     |

### 2. 核心公式 (Recursive Steps for EKF)

EKF 最大的区别在于，它用**雅可比矩阵** (Jacobian Matrix) 来代替 KF 中的 **$F$** 和 **$H$** 矩阵。

#### A. 预测阶段 (Time Update)

1. 先验状态估计:

   $$
   \hat{x}_k^- = f(\hat{x}_{k-1}^+, u_{k-1})
   $$

   (注意：这里直接将后验状态估计 $\hat{x}_{k-1}^+$ 代入非线性函数 $f$。)
2. 线性化：计算状态转移雅可比矩阵 $F_{k-1}$，这是 $f(\cdot)$ 关于状态 $x$ 的偏导数。

   $$
   F_{k-1} = \left.\frac{\partial f}{\partial x}\right|_{\hat{x}_{k-1}^+, u_{k-1}}
   $$
3. 先验误差协方差:

   $$
   P_k^- = F_{k-1} P_{k-1}^+ F_{k-1}^T + Q_{k-1}
   $$

   (公式结构与 KF 相同，但 $F_{k-1}$ 是雅可比矩阵。)

#### B. 更新阶段 (Measurement Update)

1. 线性化：计算观测雅可比矩阵 $H_k$，这是 $h(\cdot)$ 关于状态 $x$ 的偏导数。

   $$
   H_k = \left.\frac{\partial h}{\partial x}\right|_{\hat{x}_k^-}
   $$

   (在预测状态 $\hat{x}_k^-$ 处进行线性化。)
2. 卡尔曼增益:

   $$
   K_k = P_k^- H_k^T (H_k P_k^- H_k^T + R_k)^{-1}
   $$

   (公式结构与 KF 相同，但 $H_k$ 是雅可比矩阵。)
3. 后验状态估计:

   $$
   \hat{x}_k^+ = \hat{x}_k^- + K_k (z_k - h(\hat{x}_k^-))
   $$

   (注意：这里的测量残差是用实际测量 $z_k$ 减去通过非线性函数 $h(\cdot)$ 得到的预测测量。)
4. 后验误差协方差:

   $$
   P_k^+ = (I - K_k H_k) P_k^-
   $$

### 代码

{% highlight cpp %}
   #include <Eigen/Dense>
   #include `<iostream>`
   #include `<cmath>`

   class EKF_CV_Yaw {
   public:
      // 状态维度：9维
      static constexpr int STATE_DIM = 9;
      // 测量维度：6维（位置3 + 欧拉角3）
      static constexpr int MEAS_DIM  = 6;

    using StateVector = Eigen::Matrix<double, STATE_DIM, 1>;
      using StateMatrix = Eigen::Matrix<double, STATE_DIM, STATE_DIM>;
      using MeasVector  = Eigen::Matrix<double, MEAS_DIM, 1>;
      using HMatrix     = Eigen::Matrix<double, MEAS_DIM, STATE_DIM>;

    EKF_CV_Yaw() {
         x_.setZero();
         P_.setIdentity();
         P_.block<3,3>(0,0) *= 1.0;     // 位置初始不确定性
         P_.block<3,3>(3,3) *= 10.0;    // 速度不确定
         P_.block<3,3>(6,6) *= 0.5;      // yaw, yaw_rate, vz_up

    // 过程噪声 Q（调参主力）
         Q_.setZero();
         Q_(0,0) = Q_(1,1) = Q_(2,2) = 0.1;     // 加速度噪声 → 位置
         Q_(3,3) = Q_(4,4) = Q_(5,5) = 1.0;     // 速度噪声
         Q_(6,6) = 0.01;                        // yaw 加速度噪声
         Q_(7,7) = 0.1;                         // yaw_rate 噪声
         Q_(8,8) = 0.5;

    // 测量噪声 R
         R_.setIdentity();
         R_.block<3,3>(0,0) *= 0.1;   // 位置测量噪声 0.1m
         R_.block<3,3>(3,3) *= 0.02;           // 欧拉角噪声 ≈ 1.15°
      }

    /**
      * @brief 预测步（恒速 + 恒定偏航率模型）
      */
      void predict(double dt) {
         double yaw = x_(6);

    // ===== 1. 非线性状态预测 f(x) =====
         StateVector x_pred = x_;

    x_pred(0) += x_(3) * dt;                           // px += vx*dt
         x_pred(1) += x_(4) * dt;                           // py += vy*dt
         x_pred(2) += x_(5) * dt;                           // pz += vz*dt
         x_pred(6) += x_(7) * dt;                          // yaw += yaw_rate * dt
         // vx,vy,vz,yaw_rate,vz_up 不变（恒速假设）

    // 限制 yaw 在 [-pi, pi]
         if (x_pred(6) > M_PI)  x_pred(6) -= 2*M_PI;
         if (x_pred(6) < -M_PI) x_pred(6) += 2*M_PI;

    // ===== 2. 计算状态转移雅可比 F (9x9) ———— 一阶泰勒展开核心！=====
         Eigen::Matrix<double, STATE_DIM, STATE_DIM> F = Eigen::Matrix<double, STATE_DIM, STATE_DIM>::Identity();

    // 位置对速度的积分
         F(0,3) = dt;
         F(1,4) = dt;
         F(2,5) = dt;

    // yaw 对 yaw_rate 的积分
         F(6,7) = dt;

    // ===== 3. 过程噪声雅可比 G（将加速度噪声映射到状态）=====
         Eigen::Matrix<double, STATE_DIM, STATE_DIM> G = Eigen::Matrix<double, STATE_DIM, STATE_DIM>::Zero();
         G.block<3,3>(3,3) = Eigen::Matrix3d::Identity();     // 速度受加速度影响
         G(7,7) = 1.0;                                        // yaw_rate 受角加速度影响
         G(8,8) =  = 1.0;

    // ===== 4. 协方差预测 =====
         P_ = F * P_ * F.transpose() + G * Q_ * G.transpose();

    x_ = x_pred;
      }

    /**
      * @brief 更新步：测量 = [px, py, pz, roll, pitch, yaw]
      */
      void update(const MeasVector& z) {
         double yaw = x_(6);

    // ===== 1. 预测测量值 h(x) =====
         MeasVector z_pred;
         z_pred.head<3>() = x_.head<3>();                // 位置直接观测
         z_pred(3) = 0.0;                                    // roll 假设为 0（平面运动）
         z_pred(4) = 0.0;                                    // pitch 假设为 0
         z_pred(5) = yaw;                                    // yaw 直接可观

    // ===== 2. 计算观测雅可比 H (6x9) ———— 手推一阶泰勒展开！=====
         HMatrix H = HMatrix::Zero();

    // 位置部分：直接可观
         H.block<3,3>(0,0) = Eigen::Matrix3d::Identity();

    // 欧拉角部分：只 yaw 可观，且 ∂yaw/∂yaw = 1
         H(5,6) = 1.0;

    // roll/pitch 我们假设为 0，不参与更新（也可以加 IMU 融合）

    // ===== 3. 残差 =====
         MeasVector y = z - z_pred;
         // yaw 残差处理角度周期性
         if (y(5) > M_PI)  y(5) -= 2*M_PI;
         if (y(5) < -M_PI) y(5) += 2*M_PI;

    // ===== 4. 卡尔曼增益 =====
         Eigen::Matrix<double, MEAS_DIM, MEAS_DIM> S = H * P_ * H.transpose() + R_;
         Eigen::Matrix<double, STATE_DIM, MEAS_DIM> K = P_ * H.transpose() * S.inverse();

    // ===== 5. 状态更新 =====
         StateVector delta_x = K * y;
         x_ += delta_x;

    // yaw 角度限制
         if (x_(6) > M_PI)  x_(6) -= 2*M_PI;
         if (x_(6) < -M_PI) x_(6) += 2*M_PI;

    // ===== 6. 协方差更新（Joseph 形式更稳定）=====
         Eigen::Matrix<double, STATE_DIM, STATE_DIM> I = StateMatrix::Identity();
         P_ = (I - K * H) * P_ * (I - K * H).transpose() + K * R_ * K.transpose();
      }

    // 获取状态
      const StateVector& getState() const { return x_; }

    void setState(const StateVector& x) { x_ = x; }

   private:
      StateVector x_;        // 状态均值
      StateMatrix P_;        // 协方差
      StateMatrix Q_;        // 过程噪声（调参）
      Eigen::Matrix<double, MEAS_DIM, MEAS_DIM> R_;  // 测量噪声
   };
{% endhighlight cpp %}

## 单目测距

### 相机模型

#### 1. 像素坐标转图像坐标

将像素坐标 (u, v) 转换为图像坐标 (x, y) 的过程如下：

![像素与图像坐标系示意图]({{ site.baseurl }}/img/像素转图像.png)

数学表达式为：

$$
\left\{
\begin{array}{l}
  x = \frac{u - u_0}{d_x} \\[8pt]
  y = \frac{v - v_0}{d_y} \tag{1}
\end{array}
\right.
$$

> 说明：
> UV 为像素坐标系，XY 为图像坐标系。
> o是图像中心
> (u, v) 表示原始像素坐标，(x, y) 表示转换后的图像坐标；d_x 与 d_y 分别为像素的尺寸。

---

#### 2. 图像坐标转相机坐标

图像坐标转换为相机坐标的示意如下：

![图像坐标转相机坐标]({{ site.baseurl }}/img/图像转相机.png)

转换公式基于相似三角形原理为：

$$
\left\{
\begin{array}{l}
  x_c = \frac{Z_c \cdot x}{f} \\[8pt]
  y_c = \frac{Z_c \cdot y}{f} \tag{1}
\end{array}
\right.
$$

> 说明：
> – 公式中 Z_c 表示相机与目标之间的距离； 在相机坐标系中是沿相机Z轴的距离
> – 在归一化坐标系下，f 的影响可以忽略，从而简化转换过程。

### 测距算法

![测距模型]({{ site.baseurl }}/img/测距模型.png)

#### 1. 计算公式

$$
\begin{aligned}
D      &= H \cdot \tan(\alpha - \beta) \quad \text{(1)} \\[8pt]
\alpha &= \frac{\pi}{2} - pitch \quad \text{(2)} \\[8pt]
\beta  &= \arctan(y) \quad \text{(3)}
\end{aligned}
$$

> **角度说明：**
> **$\alpha$**：相机光轴与水平面的夹角。当云台 pitch 角向下倾斜时，$\alpha = \frac{\pi}{2} - pitch$ 表示从水平线到相机光轴的角度。
> **$\beta$**：从相机光轴到图像上目标投影点的角度。在相机坐标系中，该角度由归一化后的图像坐标 $y$ 计算得到，$\beta = \arctan(y)$。
> 因此，$(\alpha - \beta)$ 表示从水平线到目标投影点的角度，用于计算目标在水平方向上的距离。

#### 2. bata计算原理

![β 图]({{ site.baseurl }}/img/β.png)

> 图中：0 表示光心，p 为图像上的投影点

下面让我解释一下 $\beta$ 角的计算原理：

在相机成像原理中，$\beta$ 角表示从相机光心指向图像平面上某投影点的角度，该角度可以通过图像坐标 $y$ 来计算。

**为什么 $\beta = \arctan(y)$？**原因如下：

1. 图像坐标系中的 $y$ 值已通过相机内参矩阵归一化处理。
2. 因此，$\beta$ 就是该三角形中的角，其计算公式自然为 $\arctan(y)$。

#### 3. 计算深度

根据上述公式 (1)，D 表示 FLU 坐标系中向前的距离（对应于 flu_x）。

利用 flu_x 和勾股定理，可进一步计算深度（实际距离）：

$$
depth = \sqrt{flu_x^2 + H^2}.
$$

#### 4. 计算 yaw 角

![yaw 图]({{ site.baseurl }}/img/yaw.png)

> 正确的 yaw 角应为绿色虚线与 Zc 的夹角, 即是相机坐标系下真实目标与光心的夹角

$$
\begin{aligned}
yaw &= \arctan\left(\frac{flu_y}{flu_x}\right) \\[8pt]
    &= \arctan\left(\frac{y \cdot dist}{flu_x}\right).
\end{aligned}
$$

#### 总结

1. 利用几何关系解算位置 FLU_x = H * tan(云台向下的角度 + 接地点在图像平面投影点与相机光轴的夹角)
2. 接地点在图像平面投影点与相机光轴的夹角可以用 atan(y) 计算得到 (pitch)
3. 然后计算深度， 根据勾股定理， depth = H 平方 + FLU_x的平方然后开方
4. 计算相机坐标系下， 目标点与相机光轴的夹角(yaw)
5. 然后利用图像坐标转世界坐标计算FLU_y， 用图像点X来转换，因为x表示目标点在图像平面偏离光轴的左右程度;
6. 云台控制也利用pitch和yaw将目标保持在画面中心

## Nanotrack

### 原理

1. 模板分支提取模板图像特征，区域大小127x127
2. 搜索分支提取搜索区域图像255x255，生成特征图; 填充padding截取完整的搜索区域
3. 模板特征图(8x8)在搜索特征图上做滑动扫描，在每一个滑动位置，将对应通道的数值相乘并求和（数值越大表示互相关性越强），得到16x16的响应图
4. 分类：结合面积、长宽比变化、余弦窗口、极值等得到中心点 $grid\_x = col \times stride - 128$
5. 回归：预测目标想对于该格点的上下左右的偏移量，最后映射到图像的坐标得到最终的预测框  $x1 = grid\_x - l$，$x2 = grid\_x + r$

### 优化方法

1. 蒸馏:  选择基于 ResNet-50 的 **SiamRPN++** 作为教师。原因是我们同属 Siamese 架构，响应图的生成逻辑（互相关）一致。ResNet 提取的深层语义特征能有效指导 MobileNet 分支，提升学生模型在响应图上的 **峰值信噪比** ，减少旁瓣干扰。

# DJI PSDK

## DJI Eport 替换方案

1. 使用orin NX 作负载的时候， 不用配置USB BULK, 选择硬件连接方式DJI_USE_UART_AND_NETWORK_DEVICE
2. 使用rk3588s 作为负载时，不参照官方建议配置rndis， 直接使用网卡

   - 使用lsusb 获取网卡对应的VID和PID
   - 获取3588对应网口的名称， 修改配置文件对应配置
   - 检查串口名称，eg. `/dev/ttyUSB0`    对应修改hal_uart.h中的 `LINUX_UART_DEV1`

## 双路拉流

1. SDK模块初始化， `DjiCameraManager_Init()` 和 `DjiLiveview_Init()`
2. `DjiPayloadCamera_GetVideoStreamRemoteAddress(ipAddr, &port);`：获取 DJI 负载相机视频流的远程 IP 地址和端口号
3. 可见光、红外同步拉流

   - 启动拉流， 然后用H.264解码
   - 设计队列为帧-时间戳 std::queue<std::pair<cv::Mat, int64_t>>
   - 比较两个队列中最老帧的时间戳，丢弃时间戳较老的帧，直到两个队列的最老帧的时间戳近似相等(误差几ms)

   {% highlight cpp %}

   DjiLiveview_StartH264Stream(DJI_LIVEVIEW_CAMERA_POSITION_NO_1,
   DJI_LIVEVIEW_CAMERA_SOURCE_DEFAULT,
   &StreamDecoder::startMainCameraDecoding);

   DjiLiveview_StartH264Stream(DJI_LIVEVIEW_CAMERA_POSITION_NO_1,
   DJI_LIVEVIEW_CAMERA_SOURCE_M3T_IR,
   &StreamDecoder::startIrCameraDecoding);

   {% endhighlight %}

   {% highlight cpp %}

   bool StreamDecoder::getSynchronizedFrames(cv::Mat& mainFrame, cv::Mat& irFrame, int syncToleranceMs)
   {
   std::lock_guard[std::mutex](std::mutex) lock(frameMutex);
   const int tolerance = syncToleranceMs; // 容忍时间（毫秒）

   // 检查是否有足够的帧进行同步
   while (!mainFrameQueue.empty() && !irFrameQueue.empty())
   {
   // 获取队列头部帧的时间戳
   int64_t mainTs = mainFrameQueue.front().timestamp;
   int64_t irTs   = irFrameQueue.front().timestamp;

   // **注意**：PTS 的单位通常不是毫秒。
   // 例如：long ts_ms = ts * av_q2d(time_base) * 1000;

   long diff = std::abs(mainTs - irTs);

   if (diff <= tolerance)
   {
   // **同步成功**：时间戳匹配，取出帧并返回
   mainFrame = mainFrameQueue.front().frame;
   irFrame   = irFrameQueue.front().frame;

   mainFrameQueue.pop();
   irFrameQueue.pop();

   return true;
   }
   else if (mainTs < irTs)
   {
   std::cout << "Dropping Main Frame. Ts diff: " << diff << "ms." << std::endl;
   mainFrameQueue.pop();
   }
   else // irTs < mainTs
   {
   std::cout << "Dropping IR Frame. Ts diff: " << diff << "ms." << std::endl;
   irFrameQueue.pop();
   }
   }

   // 如果任一队列为空，则无法同步
   return false;
   }

   {% endhighlight %}

## 自定义协议MOP互联互通

1. MOP设置
   - PipelineChannelId 信道值设置为38583
   - PipelineDeviceType 信道设备类型设置为ONBOARD
   - TransmissionControlType 传输控制类型 设置为 UNRELIABLE
2. 智能盒子Mop协议主要由三部分组成：帧头、帧体（负载）、帧尾（校验）
3. 请求信息： fusion_module 0：双光 1. 地图 ， fusion_commad 0：停止 ， 1： 开始； 请求重新发送的图像块
4. 发送信息： ack_type 0： 状态， 1： 图像， data
   - fusion_result_type ：int8_t  表示是什么任务的
   - img_uuid：char 表示图像唯一性
   - seg_nums：uint16_t  图像分段数目
   - seg_current_num：uint16_t 当前分段数
   - seg_img_data：int8_t 当前分段图像内容
5. 解决丢包：
   - 选择性重传
   - 超时未收到ACK自动重传
   - 规定最大重传数和最大等待时间，不行放弃当前帧
   - 图像压缩成JPG格式压缩掉10%， 可以进一步压缩或者使用H.264来压缩

# 多无人车协同搜索

## 遇到的问题

### 小车出现摇摆的问题

原因： 在生成候选视点序列的时候，利用的是距离的代价计算
解决： 计算效益  utility = 1 / (cost + 1e3)， 这样能保证选择一个视点后能一直保证效益最高

### 小车运动兜圈问题

原因： puresuit在目标朝向和角度变化大的时候容易出现兜圈的问题
解决：
      1. 在角度大于一定阈值的时候，先转向对齐
      2. 引入角度和速度平滑因子，平滑减小线速度

### 建图歪了的情况

原因： 点云和odom没有对齐
解决:  比较时间戳对齐

### 安全策略

1. 紧急避让
2. 依次返回
3. 动态障碍物： 利用odom信息扣掉点云；反投影比较深度；

## 边界与视点生成

### 地图管理

{% highlight cpp %}
inline void SDFMap::posToIndex(const Eigen::Vector3d& pos, Eigen::Vector3i& id)
{
   for (int i = 0; i < 3; ++i)
      id(i) = std::floor((pos(i) - mp_->map_origin_(i)) * mp_->resolution_inv_);
}
{% endhighlight %}

1. 每辆车可以获得自己的其实朝向， odom
2. 每辆车自行探索自己的区域，建图，每满足200个体素索引就打包成一个chunk（相当于体素索引列表）
3. 广播自己有哪些编号的chunk， 附带无人机编号
4. 每辆车根据差异索引，odom等信息补齐自己的地图

### 边界生成

1. 合并本车当前探索的区域与其他车形成的区域
2. 如果边界在区域的重叠区域并且当前这个重叠区域的边界不是自由区域或者邻阈没有未知区域，则将边界删除； 同样的原则检查休眠边界；
3. 根据合并区域适当膨胀，但是保证在地图内， 得到新的搜索区域
4. 生成边界种子点   原则： 未被标记为边界 + 所处的位置是自由区域+邻阈未知
   {% highlight cpp %}
   // 获取 SDF 地图的整体边界框
   Vector3d box_min, box_max;
   edt_env_->sdf_map_->getBox(box_min, box_max);

   //定义搜索区域：将更新区域和外部块边界框稍微膨胀
   vector[Eigen::Vector3d](Eigen::Vector3d) search_mins, search_maxs;
   for (int i = 0; i < mins.size(); ++i)
   {
   search_mins.push_back(mins[i] - Vector3d(1, 1, 0.2));
   search_maxs.push_back(maxs[i] + Vector3d(1, 1, 0.2));

   // 限制范围在sdfmap范围内
   for (int k = 0; k < 3; ++k)
   {
   search_mins[i][k] = max(search_mins[i][k], box_min[k]);
   search_maxs[i][k] = min(search_maxs[i][k], box_max[k]);
   }
   }

   // 将搜索区域的边界框转换为体素索引
   vector[Eigen::Vector3i](Eigen::Vector3i) min_ids(mins.size()), max_ids(mins.size());
   for (int i = 0; i < mins.size(); ++i)
   {
   edt_env_->sdf_map_->posToIndex(search_mins[i], min_ids[i]);
   edt_env_->sdf_map_->posToIndex(search_maxs[i], max_ids[i]);
   }

   // 在搜索区域内扫描新的边界种子
   for (int i = 0; i < min_ids.size(); ++i)
   {
   auto min_id = min_ids[i];
   auto max_id = max_ids[i];

   for (int z = min_id(2); z <= max_id(2); ++z)
   for (int x = min_id(0); x <= max_id(0); ++x)
   for (int y = min_id(1); y <= max_id(1); ++y)
   {
   Eigen::Vector3i cur(x, y, z);
   // 检查条件：
   // 1. 未标记为边界 (frontier_flag_ == 0)
   // 2. 当前体素是已知的空闲区域 (knownfree)
   // 3. 邻居有未知区域 (isNeighborUnknown)

   if (frontier_flag_[toadr(cur)] == 0 && knownfree(cur) && isNeighborUnknown(cur))
   {
   // 从种子单元扩展，生成完整的边界簇
   expandFrontier(cur, ugv_pos);
   }
   }
   }
   {% endhighlight %}

5  扩展边界； 利用BFS， 原则： 在4的基础上加了一个地图内的检查
   {% highlight cpp %}
    queue[Eigen::Vector3i](Eigen::Vector3i) cell_queue;
    vector[Eigen::Vector3d](Eigen::Vector3d) expanded;
    Vector3d pos;

    edt_env_->sdf_map_->indexToPos(first, pos);
    expanded.push_back(pos);
    cell_queue.push(first);
    frontier_flag_[toadr(first)] = 1;

    // Search frontier cluster based on region growing (distance clustering)
    while (!cell_queue.empty())
    {
        auto cur = cell_queue.front();
        cell_queue.pop();
        auto nbrs = allNeighbors(cur);
        for (auto nbr : nbrs)
        {
            // Qualified cell should be inside bounding box and frontier cell not clustered
            int adr = toadr(nbr);
            if (frontier_flag_[adr] == 1 || !edt_env_->sdf_map_->isInBox(nbr) || !(knownfree(nbr) && isNeighborUnknown(nbr)))
                continue;

    edt_env_->sdf_map_->indexToPos(nbr, pos);

    if (pos[2] < 0.2) continue;

    expanded.push_back(pos);
            cell_queue.push(nbr);
            frontier_flag_[adr] = 1;
        }
    }
   {% endhighlight %}

### 视点生成

1. 采样位置，以边界为中心点，画三圈半径大小不同的同心圆
2. 设置条件

   - 必须在地图边界框内（isInBox）
   - 不能在障碍物膨胀区域内（getInflateOccupancy == 1）
   - 不能靠近未知区域（isNearUnknown）
3. 生成yaw

   - 取降采样后边界的第一个体素作为参考， 与采样视点作角度计算
   - 然后依次将后面的体素提取出来与采样视点作角度计算并取平均，然后与参考角度累加
   - 这样做的目的： **视野利用率最高，一次能看到最多的未知区域**

   {% highlight cpp %}
   void FrontierFinder::sampleViewpoints(Frontier &frontier)
   {
   // 在圆形区域采样视点
   // 外环控制采样半径
   for (double rc = candidate_rmin_, dr = (candidate_rmax_ - candidate_rmin_) / candidate_rnum_; rc <= candidate_rmax_ + 1e-3; rc += dr)
   // 内循环 控制角度（phi），在 [-π, π) 范围内采样圆周上的点
   for (double phi = -M_PI; phi < M_PI; phi += candidate_dphi_)
   {
   // 以边界簇平均位置为中心， 画一圈圈同心圆
   const Vector3d sample_pos = frontier.average_ + rc * Vector3d(cos(phi), sin(phi), 0);

   // 检查采样点是否合格：
   // 1. 必须在地图边界框内（isInBox）
   // 2. 不能在障碍物膨胀区域内（getInflateOccupancy == 1）
   // 3. 不能靠近未知区域（isNearUnknown）
   if (!edt_env_->sdf_map_->isInBox(sample_pos) || edt_env_->sdf_map_->getInflateOccupancy(sample_pos) == 1 || isNearUnknown(sample_pos))
   continue;

   //* 计算平均yaw角度 */
   auto &cells = frontier.filtered_cells_; //已知区域和未知区域的边界点（过滤后）
   // std::cout << "test filter cell: " << cells.size() << std::endl;
   Eigen::Vector3d ref_dir = (cells.front() - sample_pos).normalized(); // 参考方向：第一个单元到采样点的方向
   double avg_yaw = 0.0;
   for (int i = 1; i < cells.size(); ++i)
   {
   Eigen::Vector3d dir = (cells[i] - sample_pos).normalized();
   double yaw = acos(dir.dot(ref_dir));
   if (ref_dir.cross(dir)[2] < 0)
   yaw = -yaw;
   avg_yaw += yaw;
   }

   avg_yaw = avg_yaw / cells.size() + atan2(ref_dir[1], ref_dir[0]); // 计算平均偏航角度， 并加上参考方向的初始角度
   wrapYaw(avg_yaw);                                                 // 规范化到 [-π, π]

   // 计算从该视点能看到的边界单元数量
   int visib_num = countVisibleCells(sample_pos, avg_yaw, cells);
   if (visib_num > min_visib_num_)
   {
   Viewpoint vp = {sample_pos, avg_yaw, visib_num};
   frontier.viewpoints_.push_back(vp);
   // int gain = findMaxGainYaw(sample_pos, frontier, sample_yaw);
   }
   // }
   }
   }

   {% endhighlight %}

## 区域分配算法

最核心的模块就是基于刚性区域约束 + MinMax MTSP 的网格分配算法，目前稳定用于多车协同搜索。

### 问题建模（MTSP）

把问题 MTSP(多旅行商) 问题，目标是求解minmax， 即能让最慢的那辆车尽快搞完， 缩短任务完成时间

边权使用我们自己实现的 `ViewNode::computeCost`，包含了真实航程、偏航角惩罚、动力学约束

### 核心约束注入（解决实际工程问题）

我加了三层强约束和惩罚，保证实飞绝对不出事：

- **刚性区域划分**：整个地图按 x 坐标硬性切成左/中/右三块（8.33m 和 16.67m 两条线），根据无人机全局 ID（0/1/2）决定它只能探索自己负责的区块。在代价矩阵里，把本机到「非负责区」所有网格的代价直接设成 1e9（无穷大）。这样彻底杜绝交叉飞行。
- **同伴排斥惩罚**：如果两架无人机初始距离 < 10m，对「我去抢离你特别近的网格」这条边的代价乘 1~2 倍惩罚，距离越近惩罚越狠。实测这招完美解决启动时互相撞向同一个网格的问题。
- **负载均衡约束**：在 LKH 参数里强制设置 `MTSP_MIN_SIZE` 和 `MTSP_MAX_SIZE`，保证每架无人机分到的网格数量差不超过 1。

### LKH求解

LKH 创建虚拟起点，将多辆车绑定到多个虚拟起点， 然后生成从虚拟起点开始的一系列路径，在过程中， k-opt可以利用代价矩阵来更换路径，保证最优

## 去中心化方法

1. 两两配对优化，跳过以下情况

   - 比自己编号小
   - 没通信上
   - 刚尝试过优化
   - 最近互动过
   - 俩都没任务
2. 轨迹共享判断群体碰撞性

## 路径规划

### 全局与局部规划方法

1. 全局： TSP网格巡游
2. 中层： 局部最优视点序列
3. 局部： 前端A*粗略搜路， 重规划给动力学模型规划； 后端优化用B样条插值

### 决定去哪个边界的哪个视点

> 根据网格和边界的情况来生成下一个最佳视点

1. 网格为空

   - 此时要么全局路径走完或者还没规划全局路径
   - 遍历所有边界的最佳视点，这个最佳视点根据能看到最多的边界体素排序的
   - 选效益最大的， **这样做避免摇摆的情况发生**， 如果用cost会忽视掉能看到更多边界的视点，探索效率也会低下
     {% highlight cpp %}
     auto tmp_cost = ViewNode::computeCost(pos, point, yaw[0], ed_->yaws_[i], vel, yaw[1], tmp_path);
     double tmp_utility = 1.0 / (tmp_cost + 1e-3);

     if (tmp_utility > max_utility)
     {
     max_utility = tmp_utility;
     min_cost_id = i;
     }
     {% endhighlight %}
2. 当前网格没有前沿

   - 运动到下一个网格中心，然后再找最近的边界视点
3. 单一边界

   - 精炼视点，挑选排名前几的视点
   - 如果此时已经是最后一个网格了，则挑选cost最低的去
   - 如果还有网格，就把网格位置加入视点数组，然后生成完整的巡游路径，这样做可以更平滑
4. 多个前沿

   - 选几个边界，然后在这几个边界中挑选几个排名靠前的视点
   - 然后和三一样用局部巡游路径， Djikstra找访问视点的顺序，A*生成路径

#### 局部巡游的时候图是怎么建立的？

比如说，

- 有三个边界，10个视点， 依照分层建图的原则， 第一个边界的所有视点在第一层，但是没有边相连，第一层的节点连接第二层的所有节点；
- 节点包括：视点位置、最佳朝向，进入该视点的速度，id

{% highlight cpp %}
   for (int i = 0; i < n_points.size(); ++i)
   {
      // Create nodes for viewpoints of one frontier
      for (int j = 0; j < n_points[i].size(); ++j)
      {
         ViewNode::Ptr node(new ViewNode(n_points[i][j], n_yaws[i][j]));
         g_search.addNode(node);
         // Connect a node to nodes in last group
         for (auto nd : last_group)
               g_search.addEdge(nd->id_, node->id_);
         cur_group.push_back(node);

    // Only keep the first viewpoint of the last local frontier
         if (i == n_points.size() - 1)
         {
               final_node = node;
               break;
         }
      }
      // Store nodes for this group for connecting edges
      std::cout << cur_group.size() << ", ";
      last_group = cur_group;
      cur_group.clear();
   }

{% endhighlight %}

#### cost 计算

{% highlight cpp %}
   double ViewNode::computeCost(const Vector3d &p1, const Vector3d &p2, const double &y1, const double &y2, const Vector3d &v1, const double &yd1, vector `<Vector3d>` &path)
   {
      // 1. 计算位置变化代价， /最大速度，用于规一化距离成本为时间
      double pos_cost = ViewNode::searchPath(p1, p2, path) / vm_;

    // 2. 考虑速度方向变化的代价
      if (v1.norm() > 1e-3)
      {
         Vector3d dir = (p2 - p1).normalized(); //目标方向
         Vector3d vdir = v1.normalized();       //速度方向
         double diff = acos(vdir.dot(dir));     //计算速度方向和目标方向的夹角
         pos_cost += w_dir_ * diff;             // 乘一个权重 加到位置代价
      }

    // 3. 航向变化的代价
      double diff = fabs(y2 - y1);       // 计算航向角度差的绝对值
      diff = min(diff, 2 * M_PI - diff); // 考虑2派周期， 得到的是最短旋转路径
      double yaw_cost = diff / yd_;      // 用差值 除 最大航向角速度
      return max(pos_cost, yaw_cost);
   }
{% endhighlight %}

### Djikstra

#### 核心思想

**1. 初始化：** 维护一个集合，记录已找到最短路径的节点，以及一个距离数组，记录从起点到每个节点的当前最短距离。起点到自身的距离设为 0，到其他所有节点的距离设为无穷大（**$\infty$**）。

**2. 迭代：** 重复以下步骤，直到所有节点都被访问或目标节点被访问：

* 从**尚未确定最短路径的节点**中，选择一个**当前距离起点最近**的节点 **$u$**。
* 将节点 **$u$** 标记为“已确定最短路径”。
* 松弛操作 (Relaxation)： 遍历 $u$ 的所有邻接点 $v$。如果通过 $u$ 到达 $v$ 的距离更短，则更新 $v$ 的最短距离。
  $$
  \text{dist}[v] = \min(\text{dist}[v], \text{dist}[u] + \text{weight}(u, v))
  $$
* 为了记录路径，通常还需要一个**前驱（`parent`）数组**来记录到达 **$v$** 的最短路径上的前一个节点。

#### 算法原理

##### 初始化

1. 距离数组 **$\text{dist}[]$**，初始化 **$\text{dist}[\text{start}] = 0$**，其余为 **$\infty$**
2. 前驱数组 **$\text{parent}[]$**，用于路径重建, 保存的是上一个节点
3. 优先队列 **$PQ$**，存储 **$\langle \text{距离}, \text{节点ID} \rangle$**，初始将 **$\langle 0, \text{start} \rangle$** 压入

##### 循环

* 从 **$PQ$** 中取出距离最小的节点 **$u$**（及其距离 **$d$**）。
* **剪枝/优化** ：如果 **$d > \text{dist}[u]$**，说明 **$u$** 已经被更短的路径更新过，跳过本次循环。
* **松弛** ：对于 **$u$** 的每个邻居 **$v$**（边权为 **$w$**）：
* 如果 **$\text{dist}[u] + w < \text{dist}[v]$**：

  * 更新 **$\text{dist}[v] = \text{dist}[u] + w$**。
  * 设置 **$\text{parent}[v] = u$**。
  * 将 **$\langle \text{dist}[v], v \rangle$** 压入 **$PQ$**。

  {% highlight cpp %}
  #include `<algorithm>`
  #include `<iostream>`
  #include `<limits>`
  #include <math.h>
  #include `<queue>`
  #include `<vector>`

  using namespace std;

  struct Edge
  {
  int       to;
  long long weight;
  };

  using Graph     = vector<vector `<Edge>`>;              // nxn的节点图
  using PQElement = pair<int, long long>;              // 优先堆的类型
  long long INF   = numeric_limits `<long long>`::max();  //定义一个无穷大值

  vector `<int>` DjikstraPath(int start, int end, int num_nodes, const Graph& graph)
  {

  /**

  * 定义最小堆，初始化dist，prev
    */
    vector `<int>`                                                      path;
    vector `<long long>`                                                dist(num_nodes, INF);
    vector `<int>`                                                      prev(num_nodes, -1);
    priority_queue<PQElement, vector `<PQElement>`, greater `<PQElement>`> pq;

  // 定义初始节点
  dist[start] = 0;
  pq.push({ start, 0 });

  while (!pq.empty())
  {
  int       U = pq.top().first;
  long long V = pq.top().second;
  pq.pop();

  if (V > dist[U])
  {
  continue;
  }

  if (U == end)
  {
  int cur = end;
  while (cur != -1)
  {
  path.push_back(cur);
  if (cur == start)
  break;
  cur = prev[cur];
  }

  reverse(path.begin(), path.end());
  return path;
  }

  for (auto neighbor : graph[U])
  {

  int       X = neighbor.to;
  long long Y = neighbor.weight;

  if (dist[U] + Y < dist[X])
  {
  dist[X] = dist[U] + Y;
  prev[X] = U;
  pq.push({ X, dist[X] });
  }
  }
  }

  return {};
  }

  int main()
  {

  int   N = 5;
  Graph graph(5);  // 5x5

  graph[0].push_back({ 1, 2 });
  graph[0].push_back({ 2, 5 });
  graph[1].push_back({ 3, 6 });
  graph[1].push_back({ 2, 2 });
  graph[2].push_back({ 3, 7 });
  graph[2].push_back({ 4, 1 });
  graph[3].push_back({ 2, 1 });
  graph[3].push_back({ 4, 1 });

  int start = 0, end = 4;

  vector `<int>` res = DjikstraPath(start, end, N, graph);

  for (int i = 0; i < res.size(); i++)
  {
  cout << res[i] << ",";
  }
  cout << endl;

  return 0;
  }
  {% endhighlight %}

#### 复杂度计算

时间复杂度：

| **操作**                        | **执行次数**                  | **单次耗时（优先队列）** | **总耗时**          |
| ------------------------------------- | ----------------------------------- | ------------------------------ | ------------------------- |
| **取出最小元素 (`pq.pop()`)** | **$V$**次（每个节点最多出队一次） | **$O(\log V)$**        | **$O(V \log V)$** |
| **松弛操作 (`pq.push()`)**    | **$E$**次（每条边最多检查一次）   | **$O(\log V)$**        | **$O(E \log V)$** |

空间复杂度：

| **数据结构**              | **空间占用**     | **作用**                                                                                                       |
| ------------------------------- | ---------------------- | -------------------------------------------------------------------------------------------------------------------- |
| **邻接表 (`Graph`)**    | **$O(V + E)$** | 存储图结构（**$V$**个节点列表，共**$E$**条边记录）。                                                       |
| **距离数组 (`dist`)**   | **$O(V)$**     | 存储从起点到所有节点的当前最短距离。                                                                                 |
| **前驱数组 (`parent`)** | **$O(V)$**     | 用于路径重建。                                                                                                       |
| **优先队列 (`pq`)**     | 最坏**$O(E)$**       | 最坏情况下，每条边松弛操作都会导致一个元素入队，虽然许多可能是重复的。实际上，在任何时刻，其大小通常远小于**$E$**. |

#### 优缺点

##### ✅ 优点 (Advantages)

1. **全局最优解** ：能够保证找到从起点到**所有其他可达节点**的 **最短路径** ，结果是绝对准确的。
2. **效率高** ：在边的权重为非负数的情况下，优先队列优化的 Dijkstra 算法 **$O((V+E)\log V)$** 效率非常高，适用于大型稀疏图。
3. **算法简单清晰** ：核心思想是贪心策略和松弛操作，概念相对容易理解和实现。
4. **应用广泛** ：是 GPS 导航、网络路由协议（如 OSPF）等许多实际应用的基础。

##### ❌ 缺点 (Disadvantages)

1. **无法处理负权边** ：这是 Dijkstra 算法最主要的限制。如果图中有 **负权边** ，Dijkstra 算法的贪心策略就会失效，无法保证找到最短路径。

* *替代方案：* 如果存在负权边，必须使用 **Bellman-Ford 算法** (**$O(VE)$**) 或  **SPFA 算法** （在实际应用中通常很快，但最坏情况是 **$O(VE)$**）。

1. **单源计算** ：它只能解决**单源最短路径**问题（从一个起点到所有其他点）。如果需要找到所有节点对之间的最短路径，需要运行 **$V$** 次 Dijkstra，总复杂度变为 **$O(V(V+E)\log V)$**。

* *替代方案：* 所有对最短路径问题通常使用 **Floyd-Warshall 算法** (**$O(V^3)$**)。

1. **计算范围大** ：即使您只需要从 **$A$** 到 **$B$** 的路径，Dijkstra 算法在最坏情况下也可能需要探索图中的大部分区域，因为它本质上是计算从 **$A$** 到**所有**点的最短路径。

* *替代方案：* 带有启发式搜索的  **A* 算法** ，在知道目标位置的情况下，可以更快地收敛到终点。

### A*

#### 当前用到的评估函数

> 引入lambda 是为了快速收敛，牺牲最优性节省时间

$$
F_{\text{Hybrid}}(n) = G_{\text{transition}}(n) + \lambda_{\text{heu}} \times (H_{\text{pos}}(n) + w_{\theta} \times H_{\text{dir}}(n))
$$

{% highlight cpp %}
      double Astar::getTransitionCost(const VehicleState &s1, const VehicleState &s2)
      {
         double dist_cost = (s2.pos - s1.pos).norm(); // 距离惩罚
         double steer_cost = abs(s2.phi - s1.phi) * 0.1; // 转向角变化惩罚
         double vel_cost = abs(s2.v - s1.v) * 0.1;      // 速度变化惩罚
         double dir_cost = abs(s2.theta - s1.theta) * 0.1; // 航向角变化惩罚
         return dist_cost + steer_cost + vel_cost + dir_cost;
      }

    // 计算对角线距离
      double dx = fabs(x1(0) - x2(0)); // X轴的距离差
      double dy = fabs(x1(1) - x2(1)); // Y轴的距离差
      double h;

    double diag = std::min(dx, dy); // 步骤 1: 确定对角线移动的最大次数

    dx -= diag; // 步骤 2: 减去已对角线移动的X轴剩余距离
      dy -= diag; // 步骤 3: 减去已对角线移动的Y轴剩余距离

    h = sqrt(2.0) * diag + dx + dy; // 步骤 4: 对角线距离+剩余平移距离
{% endhighlight %}

- G的惩罚是基于欧式距离的
- H的惩罚包括对角线距离， 朝向一致性

#### 算法原理

A* (A-star) 算法是图搜索算法中最著名和最成功的算法之一。它通常用于**寻路**和 **图遍历** ，尤其是在有明确目标的情况下，它比 Dijkstra 算法更高效。

#### 核心思想：评估函数 **$f(n)$**

A* 算法通过引入一个**启发式函数（Heuristic Function）**来指导搜索方向，使其优先搜索靠近目标的节点，从而避免像 Dijkstra 那样“盲目”地向各个方向扩展。

A* 算法在选择下一个要探索的节点 **$n$** 时，依据一个**评估函数 **$f(n)$**** 的最小值：

$$
f(n) = g(n) + h(n)
$$

| **组成部分** | **含义**                        | **解释 (与 Dijkstra 区别)**                                                                                                           |
| ------------------ | ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| **$g(n)$** | **实际成本 (Actual Cost)**      | 从**起点**到当前节点**$n$**的 **实际最短路径成本** 。**这部分与 Dijkstra 算法的**$\text{dist}[n]$**完全相同。** |
| **$h(n)$** | **启发式成本 (Heuristic Cost)** | 从当前节点**$n$**到**目标点**的 **估计成本** 。这个估计值必须是 **可接受的 (Admissible)** 。                            |
| **$f(n)$** | **总评估成本 (Total Cost)**     | 从**起点**经过**$n$**到达**目标点**的 **总估计成本** 。算法总是优先选择**$f(n)$**最小的节点。                   |

#### 常见启发式函数

在网格地图（如游戏或机器人路径规划）中，最常用的启发式函数是：

* 曼哈顿距离 (Manhattan Distance)：用于允许四个方向移动的网格图。
  $$
  h(n) = |x_n - x_{\text{目标}}| + |y_n - y_{\text{目标}}|
  $$
* 欧几里得距离 (Euclidean Distance)：用于允许八个方向移动的网格图。
  $$
  h(n) = \sqrt{(x_n - x_{\text{目标}})^2 + (y_n - y_{\text{目标}})^2}
  $$

#### 算法步骤总结

A* 算法的步骤与 Dijkstra 非常相似，主要区别在于优先队列中存储和比较的值：

1. **初始化** ：使用两个列表/集合，`OpenList`（相当于 Dijkstra 的优先队列，存储待访问节点）和 `ClosedList`（存储已访问节点）。
2. **设置** ：

* **$\text{g\_score}[n]$** 存储 **$g(n)$**，初始化起点 **$\text{g\_score}[\text{start}] = 0$**，其他为 **$\infty$**。
* **$\text{f\_score}[n]$** 存储 **$f(n)$**，初始化 **$\text{f\_score}[\text{start}] = h(\text{start})$**，其他为 **$\infty$**。
* 将 **$\langle f(\text{start}), \text{start} \rangle$** 压入优先队列 (`OpenList`)。

3. **循环** ：当 `OpenList` 不为空时：

* 从 `OpenList` 中取出 **$f(n)$** 最小的节点 **$u$**。
* 如果 **$u$** 是目标点，则停止并重建路径。
* 对于 **$u$** 的每个邻居 **$v$**：

  * 计算通过 **$u$** 到达 **$v$** 的新 **$g$** 值：**$\text{new\_g} = \text{g\_score}[u] + \text{weight}(u, v)$**。
  * **松弛** ：如果 **$\text{new\_g} < \text{g\_score}[v]$**：
  * 更新 **$\text{g\_score}[v] = \text{new\_g}$**。
  * 更新 **$\text{f\_score}[v] = \text{g\_score}[v] + h(v)$**。
  * 记录前驱 **$\text{parent}[v] = u$**。
  * 将 **$\langle f(v), v \rangle$** 压入 `OpenList`。

  {% highlight cpp %}

  #include `<algorithm>`
  #include `<iostream>`
  #include `<limits>`
  #include <math.h>
  #include `<queue>`
  #include `<vector>`

  using namespace std;

  //定义节点，包含坐标和当前花费与预计花费
  struct Node
  {
  int x_, y_;

  long long g_score, f_score;

  Node* parent;  //记录上一节点

  Node(int x, int y) : x_(x), y_(y)
  {
  g_score = numeric_limits `<long long>`::max();
  f_score = numeric_limits `<long long>`::max();
  }
  };

  using PQElement = pair<long long, Node*>;

  // 预测未来代价
  long long HFunction(Node* a, Node* b)
  {
  return abs(a->x_ - b->x_) + abs(a->y_ - b->y_);
  }

  void Astar(vector<vector `<int>`>& map, pair<int, int> start, pair<int, int> end, vector<pair<int, int>>& path)
  {
  int R = map.size();
  if (R == 0)
  return;
  int C = map[0].size();

  vector<vector `<Node>`> nodes(R);
  for (int i = 0; i < R; i++)
  {
  nodes[i].reserve(C);
  for (int j = 0; j < C; j++)
  {
  // 只创建一次对象，并放入 vector
  nodes[i].emplace_back(i, j);
  }
  }

  //创建最小堆
  priority_queue<PQElement, vector `<PQElement>`, greater `<PQElement>`> pq;

  //定义邻居点
  int dr[4] = { -1, 1, 0, 0 };
  int dc[4] = { 0, 0, -1, 1 };

  //创建起始节点与目标节点
  auto start_node  = &nodes[start.first][start.second];
  auto target_node = &nodes[end.first][end.second];

  // 定义起始节点
  start_node->g_score = 0;
  start_node->f_score = HFunction(start_node, target_node);

  // 起始节点入堆
  pq.push({ start_node->f_score, start_node });

  while (!pq.empty())
  {
  long long U = pq.top().first;
  auto      V = pq.top().second;
  pq.pop();

  if (U > V->f_score)
  continue;

  // 建立路径
  if (V == target_node)
  {
  auto cur = target_node;
  while (cur != nullptr)
  {
  path.push_back({ cur->x_, cur->y_ });
  if (cur == start_node)
  break;
  cur = cur->parent;
  }
  reverse(path.begin(), path.end());
  }

  for (int i = 0; i < 4; i++)
  {
  int r = V->x_ + dr[i];
  int c = V->y_ + dc[i];

  //检查是否超过边界或者有障碍物
  if (r >= R || r < 0 || c >= C || c < 0 || map[r][c] == 1)
  {
  continue;
  }

  auto neighbor = &nodes[r][c];

  // 只在发现更短的实际路径时更新节点
  if (V->g_score + 1 < neighbor->g_score)
  {
  neighbor->g_score = V->g_score + 1;
  neighbor->f_score = V->g_score + 1 + HFunction(neighbor, target_node);
  neighbor->parent  = V;
  pq.push({ neighbor->f_score, neighbor });
  }
  }
  }
  }

  int main()
  {

  // 5x5地图，1代表障碍物
  vector<vector `<int>`> map = { { 0, 1, 0, 1, 0 }, { 0, 0, 0, 0, 0 }, { 1, 0, 0, 1, 0 }, { 0, 0, 1, 1, 0 }, { 1, 0, 0, 0, 0 } };

  pair<int, int> start  = { 0, 0 };
  pair<int, int> target = { 4, 4 };

  vector<pair<int, int>> path;

  Astar(map, start, target, path);

  for (size_t i = 0; i < path.size(); ++i)
  {
  cout << "(" << path[i].first << "," << path[i].second << ")" << (i == path.size() - 1 ? "" : " -> ");
  }
  cout << endl;

  return 0;
  }
  {% endhighlight %}

#### 复杂度

##### 时间复杂度

$$
\text{最坏时间复杂度} = O((V + E) \log V)
$$

**然而，A* 的实际性能优势体现在其平均/最佳时间复杂度上：**

* **平均耗时：** 当启发式函数 **$h(n)$** 优秀且具有指导性时，A* 算法只会搜索地图的一小部分（靠近目标点的区域），而不是像 Dijkstra 那样均匀地向外扩展。
  * **搜索节点数 **$V'$**:** 实际探索的节点数 **$V'$** 远小于总节点数 **$V$**。
  * **实际复杂度：** 在许多实际应用中，A* 的表现更接近于 **$O(V' \log V')$**，其中 **$V'$** 是算法实际遍历的节点数。
  * **当 **$h(n)$** 非常准确时（例如 **$h(n)$** 等于实际最短距离）：** A* 的搜索可以非常接近线性时间 **$O(V')$**.

##### 空间复杂度

| **数据结构**             | **空间占用**                   | **作用**                                                                                      |
| ------------------------------ | ------------------------------------ | --------------------------------------------------------------------------------------------------- |
| **节点数组 (`nodes`)** | **$O(V)$**                   | 存储所有节点的状态（**$g\_score, f\_score, \text{parent}, x, y$**）。这是最主要的内存占用。 |
| **优先队列 (`pq`)**    | 最坏**$O(V)$**或**$O(E)$** | 存储待探索的节点。最坏情况下与边的数量**$E$**成正比，但在稀疏网格图中为**$O(V)$**。       |
| **输入地图 (`map`)**   | **$O(V)$**                   | 存储网格障碍物信息。                                                                                |

**总空间复杂度**为：

$$
O(V)
$$

#### 优缺点总结

##### ✅ 优点 (Advantages)

1. **效率极高（定向搜索）** ：这是 A* 相较于 Dijkstra 最大的优势。通过使用启发式函数 **$h(n)$**，A* 能够将搜索重点放在接近目标点的区域，从而避免探索大量无关节点，大大节省了计算时间。
2. **保证最优解（完备性）** ：只要使用的启发式函数 **$h(n)$** 是 **可接受的 (Admissible)** （即永不夸大实际成本），A* 就能保证找到最短路径。
3. **适应性强** ：可以通过调整启发式函数来平衡搜索速度和最优性：

* **提高 **$h(n)$** 精度** ：搜索速度更快，但需确保仍是可接受的。
* **$h(n) = 0$** ：退化为 Dijkstra，保证最优但速度慢。

1. **应用广泛** ：它是游戏寻路、机器人导航、物流规划等许多领域中最常用的算法。

##### ❌ 缺点 (Disadvantages)

1. **内存消耗大** ：A* 必须存储所有已访问节点的信息（在您的代码中是整个 **$R \times C$** 的 `nodes` 数组），以便进行松弛操作和路径重建。对于非常大的地图或图，内存限制可能是一个问题。

* *Dijkstra 也需要存储所有节点的 `dist`，但 A* 对内存的压力通常更大，因为它需要存储更多的状态信息。*

1. **依赖启发式函数** ：A* 的效率和正确性**强烈依赖**于启发式函数的质量：

* **$h(n)$ 不可接受** ：如果启发式函数夸大了实际成本，A* 算法可能无法保证找到最短路径。
* **$h(n)$ 太小** ：如果启发式函数太小（接近 0），A* 的性能会接近 Dijkstra，失去定向搜索的优势。

1. **无法处理负权边** ：与 Dijkstra 算法一样，A* 算法的贪心策略依赖于边的非负权。如果图中有负权边，A* 算法会失效。

### B样条曲线插值优化

#### 什么是B样条轨迹？

1. B样条曲线是由一组控制点 $P_i$ 和一组基函数 $N_{i,k}(t)$ 加权合成的曲线
2. 其数学表达式为：

   $$
   P(t) = \sum_{i=0}^{n} P_i N_{i,k}(t)
   $$

   其中：

   - $k$ 是样条的阶数（次数为 $k-1$）
   - $t$ 是参数（通常代表时间）
   - $N_{i,k}(t)$ 是由节点向量决定的基函数，具有递归特性

#### 为什么选择B样条进行优化

1. **局部支撑性**

   - 改变某一个控制点 $P_i$，只会影响曲线上的某一小段，而不会像贝塞尔曲线或多项式曲线那样"牵一发而动全身"。
   - **优化意义**：在进行局部避障调整时，计算开销极低，不需要重新计算整条轨迹
2. **凸包性**

   - 曲线片段始终包含在其对应的控制点所构成的凸包内。
   - **优化意义**：这是避障的核心原理。如果我们保证某组控制点都在障碍物外，或者控制点构成的凸包不与障碍物相交，那么曲线本身就一定是安全的。
3. **导数的线性表示**

   - B样条的导数（速度、加速度、Jerk等）仍然是B样条，且可以表示为控制点的线性组合。
   - **优化意义**：我们可以直接通过约束控制点之间的差分，来约束整条轨迹的动力学可行性。

#### 原理与建模

轨迹优化的本质是寻找一组最优的控制点坐标，使得目标函数最小，同时满足各种约束。

**Step 1: 建立目标函数 (Objective Function)**

通常由三部分组成：

$$
J = \lambda_s J_{smoothness} + \lambda_t J_{time} + \lambda_f J_{fitness}
$$

- **平滑性** ($J_{s}$): 最小化高阶导数（如 Jerk 或 Snap）。因为导数是控制点的线性函数，这通常是一个二次规划 (Quadratic Programming) 问题。
- **时间代价** ($J_{t}$): 缩短总飞行时间。
- **相似性** ($J_{f}$): 让优化后的轨迹尽可能靠近原始参考路径。

**Step 2: 施加约束 (Constraints)**

- **起点/终点约束**：固定起始控制点和结束控制点，确保位置、速度、加速度连续。
- **安全性（避障）约束**：
  - 基于欧几里得符号距离场 (ESDF)：计算控制点到最近障碍物的距离，施加推力。
  - 或者利用凸包性：确保控制点构成的多面体不触碰障碍物。
- **动力学约束**：限制控制点之间的步长，以保证 $v < v_{max}$ 和 $a < a_{max}$。

**Step 3: 求解**

由于 B 样条的参数化特性，原本复杂的泛函优化问题简化为了针对 $n$ 个向量 $P_i$ 的数值优化问题。

- 如果约束是线性的（如动力学限制），可以使用 QP 求解器。
- 如果包含非线性避障约束，通常使用 L-BFGS 或 NLopt 等非线性优化算法。

#### 为什么在无人机上采用5次B样条

5次B样条是满足四旋翼动力学特性的最低次数

5次对应的是4阶，物理意义是snap(加加加速度)，对应的无人机控制量是姿态角加速度

### PID+puresuit控制

#### 算法步骤详解

1. 确定前视距离

   $L_d$ 是 Pure Pursuit 算法的关键调参项，它通常与车速 $v$ 相关联，以确保在不同速度下有合适的跟踪性能和稳定性：

   $$
   L_d = k \cdot v + L_{d_{min}}
   $$

   💡 **调参影响：**

   - $L_d$ 太小： 车辆反应灵敏，但容易出现震荡和不稳定的跟踪。
   - $L_d$ 太大： 跟踪过于平滑，但会欠调导致在弯道中切角过多，跟踪偏差大。
2. 寻找前视点

   - 以当前位置 $P_{current}$ 为圆心，以 $L_d$ 为半径，在参考轨迹 $P_{ref}$ 上画一个圆。
   - 找到这个圆与轨迹的交点。
   - 如果有多个交点，选择最远（即最接近前进方向）的那个交点作为前视点 $P_{target}$。
3. 计算转向角
   ![puresuit]({{ site.baseurl }}/img/puresuit.png)

   | 图中符号    | 含义                                                     | 对应推导中的角色                 |
   | ----------- | -------------------------------------------------------- | -------------------------------- |
   | $A$       | 车辆的控制参考点（通常是后轴中心）。                     | $P_{current}$ (当前位置)       |
   | $C$       | 轨迹上的前视目标点。                                     | $P_{target}$ (前视点)          |
   | $l_d$     | $A$ 到 $C$ 的直线距离（图中的 $l_d$）。            | $L_d$ (前视距离)               |
   | $L$       | 车辆的轴距（$A$ 到前轴 $B$ 的距离）。                | $L$ (轴距)                     |
   | $\delta$  | 前轮的转向角。                                           | $\delta$ (转向角)              |
   | $\alpha$  | 车辆当前航向（$A$ 处的红线）与 $AC$ 连线之间的夹角。 | $\alpha$ (相对角度/横向偏差角) |
   | $R$       | 车辆沿着圆弧$AC$ 运动的转弯半径。                      | $R$ (转弯半径)                 |
   | $O$       | 理想圆弧$AC$ 的圆心。                                  | $C$ (圆心)                     |
   | $2\alpha$ | 圆心$O$ 对应的圆心角。                                 | $2\alpha$ (圆心角)             |

   ##### 第一步：根据几何关系求解转弯半径 $R$

   我们知道：


   $$
   \sin\left(\frac{\text{圆心角}}{2}\right) = \frac{\text{弦长}/2}{\text{半径}}
   $$

   对于我们的情况：

   $$
   \sin\left(\frac{2\alpha}{2}\right) = \frac{l_d / 2}{R}
   $$

   简化后得到：

   $$
   \sin(\alpha) = \frac{l_d}{2R}
   $$

   解出转弯半径 $R$：

   $$
   R = \frac{l_d}{2 \sin(\alpha)}
   $$

   ##### 第二步：应用阿克曼转向模型求转向角 $\delta$

   车辆的运动学模型（阿克曼转向模型）描述了在给定转弯半径 $R$ 和车辆轴距 $L$ 的情况下，前轮需要转动多少角度 $\delta$：

   $$
   \tan(\delta) = \frac{L}{R}
   $$

   > 💡 **说明**：这个公式来源于前轮轴线、后轮轴线和转弯半径 $R$ 必须交于圆心 $O$ 的几何约束。
   >

   ##### 第三步：代入求得最终公式

   将第一步中推导出的 $R$ 的表达式代入阿克曼转向模型公式中：

   $$
   \tan(\delta) = \frac{L}{\left(\frac{l_d}{2 \sin(\alpha)}\right)}
   $$

   整理公式（将分母的倒数乘上去）：

   $$
   \tan(\delta) = \frac{2 L \sin(\alpha)}{l_d}
   $$

   最后，通过取反正切函数得到所需的前轮转向角 $\delta$：

   $$
   \delta = \arctan\left(\frac{2 L \sin(\alpha)}{l_d}\right)
   $$

   #### 代码中流程与优化

   ##### 目标点插值

   {% highlight cpp %}
   if (dist > path_point_threshold_)
   {
   if (dist > 0.5)
   {
   int num_interpoints = static_cast `<int>`(dist / path_point_threshold_);
   for (int i = 1; i <= num_interpoints; ++i)
   {
   geometry_msgs::Point interp_point;
   interp_point.x = last_point.x + (dx / (num_interpoints + 1)) * i;
   interp_point.y = last_point.y + (dy / (num_interpoints + 1)) * i;
   interp_point.z = last_point.z + (new_point.z - last_point.z) / (num_interpoints + 1) * i;
   path_.push_back(interp_point);
   }
   }
   }
   else
   {
   path_.push_back(new_point);
   ROS_INFO("[%s] Added new path point: x=%.3f, y=%.3f, z=%.3f, path size=%zu", car_id_.c_str(), new_point.x, new_point.y, new_point.z, path_.size());
   }
   {% endhighlight %}

   > 💡 **说明**：如果当前点与路径最后一个点的距离超过 0.5m，则进行插值；如果在 0.05 到 0.5m 之间则直接加入当前点。
   >

##### 控制逻辑

- 动态前视距离计算
  {% highlight cpp %}
  double current_linear_speed = twist.linear.x;
  double dynamic_lookahead_distance = base_lookahead_distance_ + lookahead_speed_factor_ * fabs(current_linear_speed);
  dynamic_lookahead_distance = std::min(1.5, std::max(0.4, dynamic_lookahead_distance));
  {% endhighlight %}
- 查找距离当前位置最近的路径点
  {% highlight cpp %}
  for (size_t i = 0; i < path_.size(); ++i)
  {
  double dist = hypot(path_[i].x - current_pose_.position.x, path_[i].y - current_pose_.position.y);
  if (dist < min_dist_to_car)
  {
  min_dist_to_car = dist;
  closest_point_idx = i;
  }
  }
  {% endhighlight %}
- 路径点清理

  - 根据步骤二中查找的最近的路径点，清理掉已经走过的路径点，直到距离当前位置最近的路径点的前一个点
  - 重置closest_point_idx=1
- 前视点查找

  - 计算路径点相对于当前小车位姿的距离与角度
  - 保证路径点在小车的前方
  - 距离大于等于前视距离的作为前视点
  - 如果遍历完都没有找到，则直接用路径的最后一个点作为前视点

  {% highlight cpp %}
  for (size_t i = closest_point_idx; i < path_.size(); ++i)
  {
  double dist = hypot(path_[i].x - current_pose_.position.x, path_[i].y - current_pose_.position.y);

  // 仅检查路径点是否在车体前方
  double angle_to_point = atan2(path_[i].y - current_pose_.position.y, path_[i].x - current_pose_.position.x);
  double angle_error = normalize_angle(angle_to_point - current_yaw_);
  if (fabs(angle_error) > M_PI / 2.0 && i != closest_point_idx)
  {
  continue;
  }

  if (dist >= dynamic_lookahead_distance)
  {
  lookahead_point = path_[i];
  found_lookahead = true;
  break;
  }
  }
  {% endhighlight %}
- 角度控制

  - 采用一阶低通滤波

  $$
  X_{\text{smoothed}, k} = \alpha \cdot X_{\text{smoothed}, k-1} + (1 - \alpha) \cdot X_{\text{current}, k}
  $$

  这种滤波器的核心思想是：当前的平滑值是上一周期平滑值和当前原始测量值的加权平均。

  - 角度偏差比较大的时候，原地旋转
  - 到达目的地了就调整姿态

  {% highlight cpp %}
  smoothed_angle_to_target_ = angle_smoothing_factor_ * smoothed_angle_to_target_ + (1 - angle_smoothing_factor_) * angle_to_target;
  twist.angular.z = std::min(max_angular_speed_, std::max(-max_angular_speed_, kp_angular_ * smoothed_angle_to_target_ * 1.5));
  {% endhighlight %}
- 正常巡迹

  - 引入角度和速度影响因子
  - 如果角度比较大的时候， 平滑减小线速度

  {% highlight cpp %}
  double angle_factor = std::max(0.1, 1.0 - fabs(smoothed_angle_to_target_) / M_PI);

  double speed_factor = std::min(1.0, std::max(0.0, lookahead_point.z));
  const double close_to_lookahead_threshold = 0.5;
  const double large_angle_threshold = M_PI / 4.0; // 45度

  if (distance_error < close_to_lookahead_threshold && fabs(smoothed_angle_to_target_) > large_angle_threshold)
  {
  // 靠近前视点且角度仍然大，减速旋转
  twist.linear.x = 0.0;
  twist.angular.z = std::min(max_angular_speed_, std::max(-max_angular_speed_, kp_angular_ * smoothed_angle_to_target_));
  }
  else
  {
  // 正常前进和转向
  twist.linear.x = std::min(max_linear_speed_ * speed_factor * angle_factor, kp_linear_ * distance_error);
  twist.angular.z = std::min(max_angular_speed_, std::max(-max_angular_speed_, kp_angular_ * smoothed_angle_to_target_));
  }
  {% endhighlight %}

##### PID控制

根据前面公式得到前轮转向角：

$$
\delta = \arctan\left(\frac{2 L \sin(\alpha)}{l_d}\right)
$$

因为在找前视点的时候，控制了小车前方 90 度以内，所以这个 $\alpha$ 角度不会很大，

$$
\omega \approx v \cdot \frac{2 \cdot \alpha}{L_d}
$$

然后线速度与前视距离当作控制参数的一部分，所以公式简化：

$$
\omega = K_p \cdot \alpha
$$

### 四元数转欧拉角，如何防止奇异性？ 如何防止万向锁

1. 万向锁的发生

   当中间旋转角（例如，绕 $Y$ 轴的俯仰角 $\beta$）达到 $\pm 90^{\circ}$ 时，它会将第一个旋转轴（例如 $Z$ 轴）和第三个旋转轴（例如 $X$ 轴）对齐到同一个方向（共线）。此时，两个轴的旋转效果变得一样，系统失去了一个自由度，原本应该能表示三维旋转，现在只能在二维平面上旋转。在数学上，这意味着旋转矩阵的秩（Rank）在某一特定方向上不足，导致信息丢失或奇异性。
2. 奇异性定义

   在三维空间旋转表示中，奇异性指的是欧拉角表示失效的点。
   定义：在万向锁（Gimbal Lock）发生时，两个旋转轴对齐，系统失去了表示所有旋转的能力（失去一个自由度）。
   影响：在这个奇异点上，从四元数或旋转矩阵转换到欧拉角的公式会涉及除以零或对零求平方根，导致计算不稳定或产生无穷多组解。
3. 如何解决？

   $\phi = \operatorname{atan2}(2(q_w q_x + q_y q_z), 1 - 2(q_x^2 + q_y^2))$
   $\theta = \operatorname{asin}(2(q_w q_y - q_z q_x))$
   $\psi = \operatorname{atan2}(2(q_w q_z + q_x q_y), 1 - 2(q_y^2 + q_z^2))$

   {% highlight cpp %}
   inline Eigen::Vector3d quaternionToRPY(const Eigen::Quaterniond& q)
   {
   Eigen::Vector3d rpy;
   double          sinr_cosp = 2.0 * (q.w() * q.x() + q.y() * q.z());
   double          cosr_cosp = 1.0 - 2.0 * (q.x() * q.x() + q.y() * q.y());

   // 计算roll
   rpy[0] = std::atan2(sinr_cosp, cosr_cosp);

   double sinp = 2.0 * (q.w() * q.y() - q.z() * q.x());

   // 检查奇异性
   if (std::abs(sinp) >= 1)
   rpy[1] = std::copysign(M_PI / 2.0, sinp); //返回 $\pi/2$ 并使其符号与 $\sin p$（即 $+1$ 或 $-1$）的符号一致
   else
   rpy[1] = std::asin(sinp); // 标准计算

   // 计算yaw
   double siny_cosp = 2.0 * (q.w() * q.z() + q.x() * q.y());
   double cosy_cosp = 1.0 - 2.0 * (q.y() * q.y() + q.z() * q.z());
   rpy[2]           = std::atan2(siny_cosp, cosy_cosp);

   return rpy;  // [Roll, Pitch, Yaw]
   }

   {% endhighlight %}

## 碰撞检测

   {% highlight cpp %}
        Eigen::Vector2d P_rel = (self_pos - other_pos).head<2>();
        Eigen::Vector2d V_rel = (self_vel - other_vel).head<2>();
        double dist_2d = P_rel.norm();

    // 2a. 基础位置检测 (采样点直接碰撞)
        if (dist_2d < safe_dist) return false;

    // 2b. 速度超前检测 (Time-to-Collision 预警)
        if (P_rel.dot(V_rel) < 0)
        {
            double speed_closing = -P_rel.dot(V_rel) / dist_2d; //相对速度在连线方向上投影，带符号，最后归一化
            if (speed_closing > 0.01)
            {
                double TTC = (dist_2d - safe_dist) / speed_closing;
                if (TTC < TTC_safe_threshold) return false;
            }
        }
   {% endhighlight %}

# 蔚来项目

## GIOU

GIOU = IoU −  ( Area(C − (A∪B)) / Area(C) )
{% highlight cpp %}
   // 框格式：{x_center, y_center, width, height}
   struct Box { float x, y, w, h; };

   float GIoU(const Box& a, const Box& b) {
      // 1. 转成左上角 + 右下角
      float ax1 = a.x - a.w / 2, ay1 = a.y - a.h / 2;
      float ax2 = a.x + a.w / 2, ay2 = a.y + a.h / 2;
      float bx1 = b.x - b.w / 2, by1 = b.y - b.h / 2;
      float bx2 = b.x + b.w / 2, by2 = b.y + b.h / 2;

    // 2. 交集
      float ix1 = std::max(ax1, bx1);
      float iy1 = std::max(ay1, by1);
      float ix2 = std::min(ax2, bx2);
      float iy2 = std::min(ay2, by2);
      float inter = (ix2 > ix1 && iy2 > iy1) ? (ix2 - ix1) * (iy2 - iy1) : 0.0f;

    // 3. 各自面积 + 并集
      float area_a = a.w * a.h;
      float area_b = b.w * b.h;
      float union_area = area_a + area_b - inter;

    // 4. 最小包围框 C
      float cx1 = std::min(ax1, bx1);
      float cy1 = std::min(ay1, by1);
      float cx2 = std::max(ax2, bx2);
      float cy2 = std::max(ay2, by2);
      float c_area = (cx2 - cx1) * (cy2 - cy1);

    // 5. IoU
      float iou = (union_area > 0) ? inter / union_area : 0.0f;

    // 6. GIoU
      return iou - (c_area - union_area) / c_area;
   }
{% endhighlight %}

# 标定

## 激光雷达标定

### 1. 求解 Roll **$(\alpha)$** 和 Pitch **$(\beta)$**

* **目标：** 确定激光雷达相对于重力方向（或水平面）的 **倾斜角度** 。
* **方法：**  **粒子群优化 (PSO) / 非线性优化** 。
  * **原理：** 当激光雷达的**俯仰角 **$\beta$**** 和**滚转角 **$\alpha$**** 被正确标定后，通过这些角度对原始点云进行坐标变换，使得地面点云在新的坐标系中 **最接近于一个水平面** （即 **$Z'=C$**）。
  * **代价函数 **$f$**：** 构造一个衡量**水平度**的代价函数 **$f = |A| + |B|$**，其中 **$A$** 和 **$B$** 是拟合平面 **$Z' = A x' + B y' + C$** 的斜率项。目标是 **最小化 **$f$**** 。
  * **PSO的作用：** PSO 在预设的搜索范围内，随机生成 Roll 和 Pitch 的组合（即粒子），并高效地迭代搜索，最终找到使得地面最水平的 **最佳 **$\alpha$** 和 **$\beta$** 值** 。
  * **总结：** **随机初始化 **$\rightarrow$** PSO 最小化水平度 **$\rightarrow$** 获得最优 Roll **$(\alpha)$** 和 Pitch **$(\beta)$**。**

### 2. 求解 Yaw **$(\gamma)$**

* **目标：** 确定激光雷达相对于车体或世界坐标系（通常沿行驶方向）的 **航向角** 。
* **方法：**  **基于参照物（标定物）的特征匹配和最小二乘法 (Least Squares)** 。
  * **原理：** **$\alpha$** 和 **$\beta$** 决定了 Lidar 在垂直方向上的姿态，它们相对独立于水平方向的 **航向角 **$\gamma$**** 。**$\gamma$** 需要一个 **水平面上的参考** 。
  * **参照物：** 笔记中提到了**标定杆**或 **标定物特征点** 。
  * **步骤：**
    1. 采集多帧数据，提取标定物特征点（例如标定杆的中心点或边缘）。
    2. 将这些点投影到 **水平面** （俯视图）。
    3. 使用**最小二乘法**拟合这些点形成一条直线 **$y = k x + b$**。
    4. 计算这条直线相对于 Lidar 坐标系 X 轴的夹角，通常 **$\gamma$** 的求解公式与拟合直线的斜率 **$k$** 相关：**$\gamma = \arctan(k)$**。
  * **总结：** **提取参照物特征 **$\rightarrow$** 最小二乘法拟合水平轨迹 **$\rightarrow$** 获得最优 Yaw **$(\gamma)$**。**

### 粒子群优化原理 🚀

**粒子群优化 (Particle Swarm Optimization, PSO)** 是一种 **全局优化算法** ，属于**群智能算法**的一种，用于求解复杂优化问题。它模拟了鸟群觅食的行为。

#### 核心原理

* **粒子 (Particle):** 对应于优化问题中的一个 **候选解** （即一组 **$\alpha, \beta$** 和 **$\Delta z$** 的组合）。
* **群 (Swarm):** 由所有粒子组成的集合。
* **适应度函数 (Fitness Function):** 即优化目标函数，在本例中就是 **水平度函数 **$f$**** 。算法的目标是找到使这个函数值最小（或最大）的粒子位置。

#### 优化过程

每个粒子在搜索空间中移动，其速度和方向受到以下两个最优值的影响：

1. **个体最佳位置 (**$p_{best}$**):** 是粒子自身搜索到的 **历史最佳解** （使 **$f$** 最小的位置）。
2. **全局最佳位置 (**$g_{best}$**):** 是整个粒子群迄今为止搜索到的 **最佳解** （使 **$f$** 最小的位置）。

粒子在每一次迭代中，都会根据自己的 **$p_{best}$** 和群体的 **$g_{best}$** 来更新其**速度** **$\mathbf{v}_i$** 和**位置** **$\mathbf{x}_i$**：

$$
\mathbf{v}_i^{k+1} = \omega \mathbf{v}_i^k + c_1 r_1 (\mathbf{p}_{best,i} - \mathbf{x}_i^k) + c_2 r_2 (\mathbf{g}_{best} - \mathbf{x}_i^k)
$$

$$
\mathbf{x}_i^{k+1} = \mathbf{x}_i^k + \mathbf{v}_i^{k+1}
$$

其中：

* **$k$**: 当前迭代次数。
* **$\omega$**: 惯性权重，控制粒子继承前一速度的程度。
* **$c_1, c_2$**: 加速度常数，分别控制粒子趋向 **$p_{best}$** 和 **$g_{best}$** 的权重。
* **$r_1, r_2$**: **$[0, 1]$** 范围内的随机数。

通过不断迭代更新，整个粒子群会逐渐收敛到搜索空间中的 **全局最优解** 。

## 联合标定

### 具体原理

1. 同步采集点云和图像数据
2. 分别提取点云和图像边缘
3. 给定一个起始外参，将边缘的点云投影到图像上
4. 设定代价函数，误差是投影点到图像边缘的有向距离
5. 利用非线性最小二乘求解，得到最终的外参矩阵

### 点云边缘提取原理

1. 点云降采样后体素化处理，目的是在局部做边缘化处理
2. 使用ransac多次拟合，得到平面。 多次拟合的目的是一个体素可能包含多个平面
3. 取平面与平面的连接线作为深度平滑的边缘，这些点不受发散的影响

   rasac原理：
4. 任选3个点构造一个平面模型
5. 判断其他点到这个平面的距离，范围内的称为内点
6. 找到内点最多的模型作为当前最佳平面
7. 循环多次得到最后的平面

### 非线性最小二乘法求解

1. 根据初始外参， 将点云边缘投影到图像上
2. 多个投影点与最近的边缘线有个距离，重投影误差
3. 所有距离的平方加起来，得到总误差， 越小说明外参越准

# 规划控制

## MPC算法

> MPC的基本思想是：在每个控制周期内，利用系统的数学模型预测未来一段时间（预测时域）的系统行为，然后通过求解一个优化问题，计算出一序列最优控制输入，但只应用当前时刻的第一个控制输入。下一个周期重复这个过程，形成“滚动优化”。

### 工作流程

1. **测量状态** ：在当前时刻 **$k$**，测量系统当前状态 **$x(k)$**。
2. **未来预测** ：使用预测模型，基于假设的未来控制输入序列 **$U = [u(k), u(k+1), \dots, u(k+M-1)]$**（**$M$** 为控制时域），预测未来 **$P$** 步的输出 **$Y = [y(k+1), \dots, y(k+P)]$**（**$P$** 为预测时域，通常 **$P \ge M$**）
3. 求解优化：求解优化问题，最小化代价函数 $J$。通常形式为：

$$
J = \sum_{i=1}^{P} [\|y(k+i) - r(k+i)\|_Q^2 + \|\Delta u(k+i-1)\|_R^2]
$$

- $r$ 为参考轨迹（期望输出）。
- $Q$ 和 $R$ 为权重矩阵（$Q$ 大：更注重跟踪精度；$R$ 大：更平缓控制）。
- 常包括控制增量 $\Delta u$ 以避免剧变

4. **满足约束** ：在优化过程中同时满足约束条件，如：
   - 控制量限制：$u_{min} \le u \le u_{max}$
   - 增量限制：$\Delta u_{min} \le \Delta u \le \Delta u_{max}$
   - 输出限制：$y_{min} \le y \le y_{max}$
5. **滚动执行** ：得到最优控制序列，只施加第一个动作 **$u(k)$**。
6. **循环往复** ：下一时刻 **$k+1$**，重复以上步骤（利用新测量更新状态）。

## DWA算法
